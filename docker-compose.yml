version: '3.8'

services:
  # =========================================
  # 1. DATA PLANE (PostgreSQL)
  # FIX: Healthcheck variable is corrected
  # =========================================
  postgres:
    image: postgres:15
    container_name: mlops-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - mlops-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =========================================
  # 2. ORCHESTRATION PLANE (Mage.ai)
  # FIX LOGIN AKHIR: Menggunakan perintah startup dengan DISABLE_AUTH=1
  # =========================================
  mage:
    # image: mageai/mageai:latest
    build: ./mage_pipeline
    container_name: mlops-mage
    ports:
      - "6789:6789"
    volumes:
      - ./mage_pipeline:/home/src
      - ./mage_data:/home/src/mage_data
      - ./data:/home/src/data  # Mount folder data untuk DVC
      - ./mlruns:/mlruns  # <--- TAMBAHKAN BARIS INI (Shared Volume Artifacts)
    environment:
      POSTGRES_CONNECT_STRING: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      MLFLOW_TRACKING_URI: http://mlflow:5000
      MAGE_AUTHENTICATION_ENABLED: "False" # Tambahkan ini sebagai lapisan pengaman
    command: bash -c "DISABLE_AUTH=1 mage start project_education" # <--- PERBAIKAN INI MEMAKSA AUTH MATI
    depends_on:
      postgres:
        condition: service_healthy
      mlflow:
        condition: service_started
    networks:
      - mlops-net

  # =========================================
  # 3. EXPERIMENTATION PLANE (MLflow)
  # =========================================
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.14.0  # <--- WAJIB VERSI INI
    container_name: mlops-mlflow
    ports:
      - "5000:5000"
    # Perhatikan path sqlite:///mlflow/mlflow.db
    command: mlflow server --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0
    volumes:
      - ./mlruns:/mlruns
      - ./mlflow_data:/mlflow
    networks:
      - mlops-net

  # =========================================
  # 4. SERVING PLANE (FastAPI)
  # =========================================
  backend:
    build: ./backend
    container_name: mlops-backend
    ports:
      - "8000:8000"
    volumes:
      - ./mage_pipeline/artifacts:/app/artifacts
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      POSTGRES_CONNECT_STRING: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    depends_on:
      - mlflow
      - postgres
    networks:
      - mlops-net

  # =========================================
  # 5. APPLICATION PLANE (Streamlit)
  # =========================================
  frontend:
    build: ./frontend
    container_name: mlops-frontend
    ports:
      - "8501:8501"
    environment:
      BACKEND_URL: http://backend:8000
    depends_on:
      - backend
    networks:
      - mlops-net

  # =========================================
  # 6. MONITORING PLANE (Prometheus + Grafana)
  # =========================================
  prometheus:
    image: prom/prometheus
    container_name: mlops-prometheus
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - mlops-net

  grafana:
    image: grafana/grafana
    container_name: mlops-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - mlops-net

volumes:
  postgres_data:
  grafana_data:                       # <--- TAMBAHAN BARU: Definisikan volume grafana

networks:
  mlops-net:
    driver: bridge