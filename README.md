# ğŸ“ DevMLOps: AI Education Readiness Clustering System

[![Mage.ai](https://img.shields.io/badge/Orchestration-Mage.ai-purple?style=for-the-badge)](https://mage.ai)
[![MLflow](https://img.shields.io/badge/Tracking-MLflow-0194E2?style=for-the-badge)](https://mlflow.org)
[![FastAPI](https://img.shields.io/badge/Backend-FastAPI-009688?style=for-the-badge)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-FF4B4B?style=for-the-badge)](https://streamlit.io)
[![Docker](https://img.shields.io/badge/Infrastructure-Docker-2496ED?style=for-the-badge)](https://docker.com)
[![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)

> **Production-ready MLOps pipeline for clustering Indonesian provincial education readiness using K-Means algorithm, featuring automated CI/CD/CT, comprehensive monitoring, and interactive dashboards.**

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Business Context](#-business-context)
- [System Architecture](#-system-architecture)
- [Technology Stack](#-technology-stack)
- [Key Features](#-key-features)
- [Project Structure](#-project-structure)
- [Installation Guide](#-installation-guide)
- [Usage Guide](#-usage-guide)
- [Pipeline Workflows](#-pipeline-workflows)
- [API Documentation](#-api-documentation)
- [Monitoring & Observability](#-monitoring--observability)
- [CI/CD/CT Pipeline](#-cicdct-pipeline)
- [Model Performance](#-model-performance)
- [Data Schema](#-data-schema)
- [Development Guidelines](#-development-guidelines)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

The **DevMLOps** project is a comprehensive Machine Learning Operations (MLOps) system designed to analyze and cluster the educational readiness of Indonesian provinces for implementing AI-based curriculum. The system integrates best practices from Software Engineering and Data Science to ensure reproducible, scalable, and well-monitored models.

### What Problem Does It Solve?

The Indonesian Ministry of Education aims to implement an AI-based national curriculum. However, uniform implementation would fail due to drastic differences in:

- **Infrastructure**: Computer and internet availability
- **Human Resources**: Certified teachers and basic literacy levels
- **Student Outcomes**: Assessment competency scores

This system provides **data-driven cluster analysis** to identify provinces with similar readiness levels, enabling targeted policy interventions.

---

## ğŸ’¼ Business Context

### Objectives

| Category | Description |
|----------|-------------|
| **Business Goal** | Enable targeted curriculum implementation based on provincial readiness clusters |
| **Technical Goal** | Build automated CI/CD/CT pipeline minimizing manual intervention and human errors |
| **Model Goal** | Identify homogeneous provincial groups using unsupervised clustering |

### Cluster Interpretation

```mermaid
graph LR
    A[Raw Provincial Data] --> B{K-Means Clustering}
    B --> C[Cluster 0: Low Readiness]
    B --> D[Cluster 1: Medium Readiness]
    B --> E[Cluster 2: High Readiness]

    C --> F[Policy: Basic Infrastructure<br/>Focus on Literacy & Numeracy]
    D --> G[Policy: Teacher Training<br/>Facility Upgrades]
    E --> H[Policy: Full AI Curriculum<br/>Advanced Tools]

    style C fill:#ef4444
    style D fill:#f59e0b
    style E fill:#10b981
```

**Cluster Definitions:**

- **ğŸ”´ Low (Cluster 0)**: Provinces requiring basic infrastructure (e.g., Papua, Maluku)
- **ğŸŸ¡ Medium (Cluster 1)**: Provinces needing teacher training and facility support
- **ğŸŸ¢ High (Cluster 2)**: Provinces ready for full AI curriculum implementation (e.g., Java, Bali)

---

## ğŸ—ºï¸ System Architecture

```mermaid
graph TB
    subgraph DEV["<b>DEVELOPMENT LAYER</b>"]
        DEV1["<b>ğŸ‘¨â€ğŸ’» Developer</b><br/><i>Local Development</i>"]
        DEV2["<b>ğŸ“¦ Git Local Repository</b><br/><i>Version Control</i>"]
        DEV3["<b>ğŸ” Pre-commit Hooks</b><br/>Ruff â€¢ Black â€¢ Prettier"]
        DEV4["<b>âš™ï¸ Environment Config</b><br/>dotenv â€¢ .env files"]

        DEV1 -->|code & commit| DEV2
        DEV2 -->|trigger| DEV3
        DEV3 -->|validate| DEV2
    end

    subgraph CICD["<b>VERSION CONTROL & CI/CD LAYER</b>"]
        VCS1["<b>ğŸŒ GitHub Repository</b><br/><i>Source Code</i>"]
        VCS2["<b>âš¡ GitHub Actions</b><br/><i>Automation Pipeline</i>"]
        VCS3["<b>ğŸ“Š DVC</b><br/><i>Data Version Control</i>"]

        DEV2 -->|push| VCS1
        VCS1 -->|trigger| VCS2

        subgraph CI["CI Pipeline Stages"]
            CI1["<b>âœ¨ Code Quality</b><br/>Ruff + Black"]
            CI2["<b>ğŸ›¡ï¸ Security Scan</b><br/>Bandit"]
            CI3["<b>ğŸ§ª Unit Tests</b><br/>pytest"]
            CI4["<b>ğŸ”’ Container Scan</b><br/>Trivy"]

            VCS2 --> CI1 --> CI2 --> CI3 --> CI4
        end
    end

    subgraph INFRA["<b>INFRASTRUCTURE LAYER</b>"]
        DOCKER["<b>ğŸ³ Docker Engine</b>"]
        COMPOSE["<b>ğŸ¼ Docker Compose</b><br/><i>Multi-Container Orchestrator</i>"]
        NETWORK["<b>ğŸŒ Docker Network</b><br/>mlops-net"]

        DOCKER --> COMPOSE --> NETWORK
    end

    subgraph STORAGE["<b>DATA STORAGE LAYER</b>"]
        DB1["<b>ğŸ—„ï¸ PostgreSQL</b><br/>Port 5432<br/><i>education_features table</i>"]
        DB2["<b>ğŸ“ Local File System</b><br/><i>CSV Data Storage</i>"]
        DB3["<b>ğŸ’¾ DVC Storage</b><br/><i>Versioned Datasets</i>"]
        VOL1["<b>ğŸ“¦ Docker Volumes</b><br/>postgres_data<br/>grafana_data<br/>prometheus_data"]

        DB2 -.->|version control| DB3
        DB1 -.->|persist| VOL1
    end

    subgraph PIPELINE["<b>DATA PIPELINE LAYER - MAGE AI</b>"]
        MAGE["<b>ğŸ¨ Mage AI Server</b><br/>Port 6789<br/><i>Pipeline Orchestrator</i>"]

        subgraph ETL["ETL Pipelines"]
            ETL1["<b>ğŸ“¥ Data Seeding</b><br/>CSV â†’ PostgreSQL"]
            ETL2["<b>ğŸ”„ Training Pipeline</b><br/>Load â†’ Transform â†’ Train"]
        end

        subgraph BLOCKS["Pipeline Blocks"]
            BLOCK1["<b>ğŸ“– Data Loaders</b><br/>load_education_features"]
            BLOCK2["<b>ğŸ”§ Transformers</b><br/>clean_outliers_iqr<br/>transform_standardize"]
            BLOCK3["<b>ğŸ’¾ Data Exporters</b><br/>train_kmeans_clustering"]
            BLOCK4["<b>ğŸ¨ Custom Blocks</b><br/>SHAP â€¢ Visualizations"]
        end

        MAGE --> ETL1
        MAGE --> ETL2
        ETL2 --> BLOCK1 --> BLOCK2 --> BLOCK3 --> BLOCK4
    end

    subgraph ML["<b>MACHINE LEARNING TRAINING LAYER</b>"]
        subgraph OPT["Hyperparameter Optimization"]
            OPT1["<b>ğŸ¯ Optuna Study</b><br/>k = 2 to 6 clusters<br/>15 trials"]
            OPT2["<b>ğŸ“Š Objective Function</b><br/>Silhouette - 0.3Ã—DB Index"]
        end

        subgraph MODEL["Model Training"]
            ML1["<b>ğŸ¤– K-Means Clustering</b><br/>Scikit-learn<br/><i>Unsupervised Learning</i>"]
            ML2["<b>ğŸ“ StandardScaler</b><br/><i>Feature Normalization</i>"]
        end

        subgraph ARTIFACTS["Model Artifacts"]
            ART1["<b>ğŸ’¾ kmeans_model.pkl</b>"]
            ART2["<b>ğŸ“ standard_scaler.pkl</b>"]
            ART3["<b>ğŸ“„ cluster_metadata.json</b>"]
        end

        BLOCK3 --> OPT1 --> OPT2 --> ML1
        BLOCK2 --> ML2
        ML1 --> ART1
        ML2 --> ART2
        ML1 --> ART3
    end

    subgraph TRACK["<b>ML TRACKING & REGISTRY LAYER</b>"]
        MLF1["<b>ğŸ“Š MLflow Server</b><br/>Port 5000<br/><i>Experiment Tracking</i>"]
        MLF2["<b>ğŸ”¬ Experiments</b><br/>project_education_clustering"]
        MLF3["<b>ğŸ›ï¸ Model Registry</b><br/><i>Versioned Models</i>"]
        MLF4["<b>ğŸ“ˆ Metrics Store</b><br/>Silhouette â€¢ DB Index â€¢ Inertia"]

        MLF1 --> MLF2
        MLF1 --> MLF3
        MLF1 --> MLF4

        BLOCK3 -->|log experiments| MLF1
        ART1 -->|register| MLF3
    end

    subgraph EXPLAIN["<b>MODEL EXPLAINABILITY LAYER</b>"]
        SHAP1["<b>ğŸ§  SHAP Analysis</b><br/><i>Feature Importance</i>"]
        SHAP2["<b>ğŸ” KernelExplainer</b><br/><i>Model Interpretation</i>"]
        SHAP3["<b>ğŸ“Š Summary Plots</b><br/><i>PNG Visualizations</i>"]

        BLOCK4 --> SHAP1 --> SHAP2 --> SHAP3
    end

    subgraph DRIFT["<b>DATA QUALITY & DRIFT LAYER</b>"]
        EVID1["<b>ğŸ¯ Evidently AI</b><br/><i>Drift Detection Engine</i>"]
        EVID2["<b>ğŸ“‰ Statistical Tests</b><br/>Kolmogorov-Smirnov"]
        EVID3["<b>ğŸ“„ HTML Reports</b><br/>data_drift_report.html"]
        EVID4["<b>ğŸ“Š Drift Metrics</b><br/>drift_score<br/>drift_status"]

        BLOCK2 --> EVID1 --> EVID2
        EVID2 --> EVID3
        EVID2 --> EVID4
    end

    subgraph API["<b>BACKEND API LAYER</b>"]
        API1["<b>âš¡ FastAPI Server</b><br/>Port 8000<br/><i>High-Performance API</i>"]
        API2["<b>ğŸŒ REST Endpoints</b><br/>/ â€¢ /predict â€¢ /metrics"]
        API3["<b>âœ… Pydantic Validation</b><br/><i>Request/Response Schema</i>"]
        API4["<b>ğŸ“„ Model Loading</b><br/><i>Artifact Management</i>"]

        API1 --> API2
        API1 --> API3
        API1 --> API4

        ART1 -.->|load| API4
        ART2 -.->|load| API4
        ART3 -.->|load| API4
    end

    subgraph FRONT["<b>FRONTEND DASHBOARD LAYER</b>"]
        STREAM["<b>ğŸ¨ Streamlit Server</b><br/>Port 8501<br/><i>Interactive Web Interface</i>"]

        subgraph UI["User Interfaces"]
            UI1["<b>ğŸ‘¥ User Dashboard</b><br/>Cluster Visualization<br/>Interactive Maps"]
            UI2["<b>ğŸ”§ Admin Dashboard</b><br/>Pipeline Control<br/>Data Management"]
            UI3["<b>ğŸ“Š Monitoring</b><br/>Drift Reports<br/>System Health"]
        end

        subgraph VIZ["Visualization Libraries"]
            VIZ1["<b>ğŸ“ˆ Plotly</b><br/><i>Interactive Maps</i>"]
            VIZ2["<b>ğŸ“Š Altair</b><br/><i>Statistical Charts</i>"]
            VIZ3["<b>ğŸ“‰ Statsmodels</b><br/><i>Statistical Analysis</i>"]
            VIZ4["<b>ğŸ¼ Pandas</b><br/><i>Data Processing</i>"]
        end

        STREAM --> UI1
        STREAM --> UI2
        STREAM --> UI3

        UI1 --> VIZ1
        UI1 --> VIZ2
        UI2 --> VIZ3
        UI3 --> VIZ4
    end

    subgraph MONITOR["<b>MONITORING & OBSERVABILITY LAYER</b>"]
        subgraph METRICS["Metrics Collection"]
            PROM1["<b>ğŸ”¥ Prometheus</b><br/>Port 9090<br/><i>Metrics Database</i>"]
            PROM2["<b>ğŸ”® Pushgateway</b><br/>Port 9091<br/><i>Batch Metrics</i>"]
            PROM3["<b>ğŸ“¦ cAdvisor</b><br/><i>Container Metrics</i>"]
            PROM4["<b>ğŸ–¥ï¸ Node Exporter</b><br/><i>System Metrics</i>"]
        end

        subgraph SOURCE["Metrics Sources"]
            MET1["<b>âš¡ API Metrics</b><br/>http_requests_total<br/>latency â€¢ errors"]
            MET2["<b>ğŸ“Š Drift Metrics</b><br/>evidently_data_drift_*"]
            MET3["<b>ğŸ“¦ Container Stats</b><br/>CPU â€¢ Memory â€¢ Disk"]
            MET4["<b>ğŸ–¥ï¸ Host Stats</b><br/>System Resources"]
        end

        subgraph VIS["Visualization"]
            GRAF1["<b>ğŸ“Š Grafana</b><br/>Port 3000<br/><i>Monitoring Dashboards</i>"]
            GRAF2["<b>ğŸ“ˆ MLOps Overview</b><br/>API Performance"]
            GRAF3["<b>ğŸ¯ Drift Monitoring</b><br/>Data Quality"]
            GRAF4["<b>ğŸ¥ Infrastructure</b><br/>Resource Usage"]
        end

        subgraph ALERT["Alerting System"]
            ALERT1["<b>ğŸš¨ Alertmanager</b><br/>Port 9093<br/><i>Alert Routing</i>"]
            ALERT2["<b>âš ï¸ Alert Rules</b><br/>prometheus/alert_rules.yml"]
            ALERT3["<b>ğŸ“§ Notifications</b><br/>Email â€¢ Webhook"]
        end

        API2 -->|expose| MET1
        EVID4 -->|push| PROM2
        PROM3 --> MET3
        PROM4 --> MET4

        MET1 -->|scrape| PROM1
        PROM2 -->|scrape| PROM1
        MET3 -->|scrape| PROM1
        MET4 -->|scrape| PROM1

        PROM1 --> GRAF1
        GRAF1 --> GRAF2
        GRAF1 --> GRAF3
        GRAF1 --> GRAF4

        PROM1 --> ALERT1
        ALERT2 --> ALERT1
        ALERT1 --> ALERT3
    end

    subgraph SERVE["<b>ARTIFACT STORAGE & SERVING LAYER</b>"]
        NGINX["<b>ğŸŒ Nginx Server</b><br/>Port 8080<br/><i>Static File Server</i>"]
        STORE1["<b>ğŸ“ Artifacts Directory</b><br/>/artifacts/"]
        STORE2["<b>ğŸ“Š Visualizations</b><br/>elbow â€¢ PCA â€¢ silhouette"]
        STORE3["<b>ğŸ§  SHAP Plots</b><br/>shap_summary.png"]
        STORE4["<b>ğŸ“„ Drift Reports</b><br/>data_drift_report.html"]

        NGINX --> STORE1
        STORE1 --> STORE2
        STORE1 --> STORE3
        STORE1 --> STORE4

        BLOCK4 --> STORE2
        SHAP3 --> STORE3
        EVID3 --> STORE4
    end

    subgraph USERS["<b>EXTERNAL USERS & INTERACTIONS</b>"]
        USER1["<b>ğŸ‘¤ End User</b><br/><i>Web Browser</i>"]
        ADMIN1["<b>ğŸ‘¨â€ğŸ’¼ Admin User</b><br/><i>Pipeline Management</i>"]
        API_CLIENT["<b>ğŸ¤– API Client</b><br/><i>External Systems</i>"]

        USER1 -->|access dashboard| STREAM
        ADMIN1 -->|manage system| STREAM
        API_CLIENT -->|POST /predict| API1

        STREAM -->|API calls| API1
        UI2 -->|trigger pipeline| MAGE
        UI3 -->|view reports| NGINX
    end

    %% Data Flow Connections
    DB2 -->|upload CSV| ETL1
    ETL1 -->|insert data| DB1
    DB1 -->|query data| BLOCK1

    %% Monitoring Connections
    COMPOSE -.->|container metrics| PROM3
    DOCKER -.->|system metrics| PROM4

    %% Network Connections
    NETWORK -.->|connect| MAGE
    NETWORK -.->|connect| MLF1
    NETWORK -.->|connect| API1
    NETWORK -.->|connect| STREAM
    NETWORK -.->|connect| DB1
    NETWORK -.->|connect| PROM1
    NETWORK -.->|connect| GRAF1
    NETWORK -.->|connect| NGINX

    %% Enhanced Styling dengan warna yang lebih jelas dan kontras tinggi
    classDef devStyle fill:#E3F2FD,stroke:#1565C0,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef cicdStyle fill:#F3E5F5,stroke:#6A1B9A,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef infraStyle fill:#E8F5E9,stroke:#2E7D32,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef storageStyle fill:#FFF9C4,stroke:#F57F17,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef pipelineStyle fill:#E1F5FE,stroke:#0277BD,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef mlStyle fill:#FFE0B2,stroke:#E65100,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef trackStyle fill:#F8BBD0,stroke:#C2185B,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef explainStyle fill:#D1C4E9,stroke:#512DA8,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef driftStyle fill:#FFCCBC,stroke:#D84315,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef apiStyle fill:#B2DFDB,stroke:#00695C,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef frontStyle fill:#F0F4C3,stroke:#9E9D24,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef monitorStyle fill:#CFD8DC,stroke:#37474F,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef serveStyle fill:#C5E1A5,stroke:#558B2F,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px
    classDef userStyle fill:#FFCDD2,stroke:#C62828,stroke-width:3px,color:#000000,font-weight:bold,font-size:14px

    class DEV1,DEV2,DEV3,DEV4 devStyle
    class VCS1,VCS2,VCS3,CI1,CI2,CI3,CI4 cicdStyle
    class DOCKER,COMPOSE,NETWORK infraStyle
    class DB1,DB2,DB3,VOL1 storageStyle
    class MAGE,ETL1,ETL2,BLOCK1,BLOCK2,BLOCK3,BLOCK4 pipelineStyle
    class OPT1,OPT2,ML1,ML2,ART1,ART2,ART3 mlStyle
    class MLF1,MLF2,MLF3,MLF4 trackStyle
    class SHAP1,SHAP2,SHAP3 explainStyle
    class EVID1,EVID2,EVID3,EVID4 driftStyle
    class API1,API2,API3,API4 apiStyle
    class STREAM,UI1,UI2,UI3,VIZ1,VIZ2,VIZ3,VIZ4 frontStyle
    class PROM1,PROM2,PROM3,PROM4,MET1,MET2,MET3,MET4,GRAF1,GRAF2,GRAF3,GRAF4,ALERT1,ALERT2,ALERT3 monitorStyle
    class NGINX,STORE1,STORE2,STORE3,STORE4 serveStyle
    class USER1,ADMIN1,API_CLIENT userStyle
```

### Architecture Layers Overview

Sistem DevMLOps dibangun dengan arsitektur berlapis yang memisahkan concern secara jelas untuk memastikan skalabilitas, maintainability, dan observability. Berikut adalah penjelasan setiap layer:

| Layer | Components | Purpose | Key Technologies |
|-------|-----------|---------|-----------------|
| **Development Layer** | Git, Pre-commit Hooks, Environment Config | Local development workflow dengan automated code quality checks | Git, Pre-commit, Ruff, Black, Prettier, dotenv |
| **Version Control & CI/CD Layer** | GitHub, GitHub Actions, DVC | Source code versioning, automated testing, dan data versioning | GitHub Actions, DVC, pytest, Bandit, Trivy |
| **Infrastructure Layer** | Docker, Docker Compose | Container orchestration dan network management | Docker, Docker Compose |
| **Data Storage Layer** | PostgreSQL, Local Filesystem, DVC | Persistent data storage dan versioning | PostgreSQL, DVC, Docker Volumes |
| **Data Pipeline Layer** | Mage AI | ETL orchestration dan workflow automation | Mage AI, Python |
| **ML Training Layer** | Scikit-learn, Optuna | Model training dan hyperparameter optimization | Scikit-learn, Optuna, StandardScaler |
| **ML Tracking & Registry Layer** | MLflow | Experiment tracking dan model registry | MLflow |
| **Model Explainability Layer** | SHAP | Model interpretation dan feature importance | SHAP (KernelExplainer) |
| **Data Quality & Drift Layer** | Evidently AI | Data drift detection dan quality monitoring | Evidently AI |
| **Backend API Layer** | FastAPI | High-performance REST API serving | FastAPI, Pydantic, Uvicorn |
| **Frontend Dashboard Layer** | Streamlit | Interactive web interface untuk users dan admins | Streamlit, Plotly, Altair, Statsmodels, Pandas |
| **Monitoring & Observability Layer** | Prometheus, Grafana, Alertmanager | Metrics collection, visualization, dan alerting | Prometheus, Grafana, Alertmanager, cAdvisor, Node Exporter, Pushgateway |
| **Artifact Storage & Serving Layer** | Nginx | Static file serving untuk visualizations dan reports | Nginx |
| **External Users Layer** | Web Browsers, API Clients | User interactions dan external integrations | HTTP/REST |

---

## ğŸ› ï¸ Technology Stack

### Core Technologies

Berikut adalah stack teknologi lengkap yang digunakan dalam proyek DevMLOps, dikategorikan berdasarkan fungsinya:

#### 1. **Orchestration & Pipeline Management**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **Mage AI** | Latest | ETL pipeline orchestration, workflow automation, dan scheduled tasks | [docs.mage.ai](https://docs.mage.ai) |

**Why Mage AI?**
- Visual pipeline builder dengan Python-first approach
- Built-in data quality checks dan observability
- Native integration dengan PostgreSQL, MLflow, dan cloud storage
- Real-time monitoring dan debugging capabilities
- Support untuk batch dan streaming pipelines

#### 2. **Machine Learning & Data Science**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **Scikit-learn** | 1.5.2 | K-Means clustering implementation, StandardScaler, metrics | [scikit-learn.org](https://scikit-learn.org) |
| **Optuna** | Latest | Hyperparameter optimization dengan Bayesian approach | [optuna.org](https://optuna.org) |
| **SHAP** | Latest | Model explainability dan feature importance analysis | [shap.readthedocs.io](https://shap.readthedocs.io) |

**Machine Learning Workflow:**
```
Raw Data â†’ Scikit-learn (Preprocessing) â†’ Optuna (HPO) â†’ Scikit-learn (Training) â†’ SHAP (Explainability)
```

#### 3. **Experiment Tracking & Model Management**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **MLflow** | 2.14.0 | Experiment tracking, model registry, dan artifact storage | [mlflow.org](https://mlflow.org) |

**MLflow Capabilities:**
- **Tracking**: Log parameters, metrics, dan visualizations setiap training run
- **Model Registry**: Versioning model dengan tagging (Staging, Production, Archived)
- **Artifact Store**: Simpan model binaries (.pkl), scalers, dan metadata (.json)
- **UI Dashboard**: Web interface untuk compare experiments dan manage models

#### 4. **Data Version Control**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **DVC** | Latest | Dataset versioning, remote storage sync, dan reproducibility | [dvc.org](https://dvc.org) |

**DVC Workflow:**
```
dvc add data/raw/dataset.csv â†’ dvc push â†’ Git commit .dvc files â†’ Reproducible data snapshots
```

#### 5. **Data Quality & Drift Detection**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **Evidently AI** | 0.6.0 | Data drift detection, data quality checks, dan model monitoring | [evidentlyai.com](https://evidentlyai.com) |

**Evidently Capabilities:**
- **Data Drift**: Kolmogorov-Smirnov test per feature
- **Data Quality**: Missing values, duplicates, correlations
- **Model Performance**: Classification/regression metrics monitoring
- **Reports**: Interactive HTML reports dan JSON metrics

#### 6. **Backend API Framework**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **FastAPI** | Latest | High-performance REST API dengan async support | [fastapi.tiangolo.com](https://fastapi.tiangolo.com) |
| **Pydantic** | Latest (bundled) | Data validation dan serialization | [docs.pydantic.dev](https://docs.pydantic.dev) |
| **Uvicorn** | Latest | ASGI server untuk FastAPI | [uvicorn.org](https://uvicorn.org) |

**FastAPI Features:**
- Automatic OpenAPI/Swagger documentation
- Pydantic schemas untuk type safety
- Prometheus metrics integration
- Sub-100ms inference latency

#### 7. **Frontend Dashboard**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **Streamlit** | Latest | Interactive web dashboards tanpa JavaScript | [streamlit.io](https://streamlit.io) |
| **Plotly** | Latest | Interactive maps dan charts | [plotly.com/python](https://plotly.com/python) |
| **Altair** | Latest | Declarative statistical visualizations | [altair-viz.github.io](https://altair-viz.github.io) |
| **Statsmodels** | Latest | Statistical analysis dan modeling | [statsmodels.org](https://statsmodels.org) |
| **Pandas** | Latest | Data manipulation dan analysis | [pandas.pydata.org](https://pandas.pydata.org) |

**Dashboard Architecture:**
```
Streamlit App â†’ API Calls (FastAPI) â†’ Model Inference â†’ Plotly/Altair Visualizations
```

#### 8. **Database**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **PostgreSQL** | 15 | Relational database untuk education features | [postgresql.org](https://postgresql.org) |

**Database Schema:**
- **Table**: `education_features`
- **Columns**: 20 features + `provinsi` (primary key)
- **Persistence**: Docker volume (`postgres_data`)

#### 9. **Monitoring & Observability**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **Prometheus** | Latest | Metrics collection dan time-series database | [prometheus.io](https://prometheus.io) |
| **Grafana** | Latest | Visualization dashboards dan alerting | [grafana.com](https://grafana.com) |
| **Alertmanager** | Latest | Alert routing dan notification management | [prometheus.io/docs/alerting](https://prometheus.io/docs/alerting/latest/alertmanager) |
| **cAdvisor** | Latest | Container resource usage metrics | [github.com/google/cadvisor](https://github.com/google/cadvisor) |
| **Node Exporter** | Latest | Host system metrics (CPU, memory, disk) | [github.com/prometheus/node_exporter](https://github.com/prometheus/node_exporter) |
| **Pushgateway** | Latest | Batch job metrics collection | [prometheus.io/docs/practices/pushing](https://prometheus.io/docs/practices/pushing) |

**Monitoring Stack Flow:**
```
API/Services â†’ Prometheus (scrape) â†’ Grafana (visualize) â†’ Alertmanager (notify)
               â†‘
         cAdvisor + Node Exporter (system metrics)
               â†‘
         Pushgateway (batch metrics dari Mage)
```

#### 10. **CI/CD & DevOps Tools**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **GitHub Actions** | N/A | CI/CD automation workflows | [docs.github.com/actions](https://docs.github.com/actions) |
| **Pre-commit** | Latest | Git hooks untuk automated checks sebelum commit | [pre-commit.com](https://pre-commit.com) |
| **Ruff** | Latest | Extremely fast Python linter (pengganti Flake8 + isort) | [docs.astral.sh/ruff](https://docs.astral.sh/ruff) |
| **Black** | Latest | Opinionated Python code formatter | [black.readthedocs.io](https://black.readthedocs.io) |
| **Prettier** | Latest | Code formatter untuk YAML, JSON, Markdown | [prettier.io](https://prettier.io) |
| **pytest** | Latest | Python testing framework | [pytest.org](https://pytest.org) |
| **Bandit** | Latest | Security linter untuk Python code | [bandit.readthedocs.io](https://bandit.readthedocs.io) |
| **Trivy** | Latest | Container vulnerability scanner | [aquasecurity.github.io/trivy](https://aquasecurity.github.io/trivy) |
| **dotenv** | Latest | Environment variable management | [pypi.org/project/python-dotenv](https://pypi.org/project/python-dotenv) |

**CI/CD Pipeline Stages:**
```mermaid
graph LR
    A[Git Push] --> B[Pre-commit Hooks]
    B --> C[GitHub Actions]
    C --> D[Ruff + Black]
    D --> E[Bandit Security]
    E --> F[pytest Tests]
    F --> G[Docker Build]
    G --> H[Trivy Scan]
    H --> I{All Pass?}
    I -->|Yes| J[Deploy]
    I -->|No| K[Fail & Notify]
```

#### 11. **Containerization & Infrastructure**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **Docker** | Latest | Application containerization | [docker.com](https://docker.com) |
| **Docker Compose** | Latest | Multi-container orchestration | [docs.docker.com/compose](https://docs.docker.com/compose) |
| **Nginx** | Latest | Static file server untuk artifacts | [nginx.org](https://nginx.org) |

**Container Architecture:**
```
docker-compose.yml
â”œâ”€â”€ backend (FastAPI)
â”œâ”€â”€ frontend (Streamlit)
â”œâ”€â”€ mage (Mage AI)
â”œâ”€â”€ mlflow (MLflow Server)
â”œâ”€â”€ postgres (PostgreSQL)
â”œâ”€â”€ prometheus (Prometheus)
â”œâ”€â”€ grafana (Grafana)
â”œâ”€â”€ alertmanager (Alertmanager)
â”œâ”€â”€ pushgateway (Pushgateway)
â”œâ”€â”€ cadvisor (cAdvisor)
â”œâ”€â”€ node-exporter (Node Exporter)
â””â”€â”€ nginx (Artifact Server)
```

#### 12. **Version Control**

| Technology | Version | Purpose | Documentation |
|-----------|---------|---------|---------------|
| **Git** | 2.30+ | Distributed version control | [git-scm.com](https://git-scm.com) |
| **GitHub** | N/A | Remote repository hosting | [github.com](https://github.com) |

### Technology Stack Summary

**Programming Languages:**
- Python 3.9+ (primary)
- SQL (PostgreSQL queries)
- YAML (configuration files)
- Markdown (documentation)

**Infrastructure as Code:**
- Docker Compose YAML
- Prometheus alert rules YAML
- Mage AI pipeline YAML

**Total Tools Count: 20**

1. Mage AI âœ…
2. MLflow âœ…
3. Evidently AI âœ…
4. Prometheus âœ…
5. Grafana âœ…
6. Alertmanager âœ…
7. GitHub Actions âœ…
8. Optuna âœ…
9. SHAP âœ…
10. Ruff âœ…
11. Black âœ…
12. Prettier âœ…
13. pytest âœ…
14. dotenv âœ…
15. Bandit âœ…
16. Trivy âœ…
17. Streamlit âœ…
18. FastAPI âœ…
19. DVC âœ…
20. Git & GitHub âœ…
21. Pre-commit âœ…
22. PostgreSQL âœ…
23. cAdvisor âœ…
24. Node Exporter âœ…
25. Pushgateway âœ…
26. Plotly âœ…
27. Altair âœ…
28. Statsmodels âœ…
29. Pandas âœ…
30. Docker âœ…
31. Docker Compose âœ…
32. Nginx âœ…
33. Scikit-learn âœ…

### Infrastructure Stack Visualization

```mermaid
graph TD
    A[Docker Compose Orchestration] --> B[Application Services]
    A --> C[Monitoring Services]
    A --> D[Infrastructure Services]

    B --> B1[Backend: FastAPI]
    B --> B2[Frontend: Streamlit]
    B --> B3[Pipeline: Mage AI]
    B --> B4[Tracking: MLflow]

    C --> C1[Metrics: Prometheus]
    C --> C2[Visualization: Grafana]
    C --> C3[Alerting: Alertmanager]
    C --> C4[Container Metrics: cAdvisor]
    C --> C5[System Metrics: Node Exporter]
    C --> C6[Batch Metrics: Pushgateway]

    D --> D1[Database: PostgreSQL]
    D --> D2[File Server: Nginx]
    D --> D3[Network: mlops-net]
    D --> D4[Volumes: Data Persistence]

    style A fill:#2496ed
    style B fill:#009688
    style C fill:#ef4444
    style D fill:#10b981
```

---

## âœ¨ Key Features

### 1. **Automated Data Pipeline** ğŸ”„
- **Orchestrated ETL** with Mage AI
- **Automated data cleaning**: Missing value imputation, outlier removal (IQR method)
- **Feature engineering**: Standardization with StandardScaler
- **Data versioning** with DVC for reproducibility

### 2. **Intelligent ML Training** ğŸ§ 
- **Hyperparameter optimization** using Optuna (k=2-6 clusters)
- **Multi-metric evaluation**: Silhouette Score, Davies-Bouldin Index, Inertia
- **Dynamic cluster labeling**: Anti-label-switching mechanism
- **Model explainability**: SHAP summary plots

### 3. **Comprehensive Experiment Tracking** ğŸ“Š
- **MLflow integration** for all training runs
- **Model registry** with versioning
- **Artifact storage**: Models, scalers, visualizations
- **Metadata tracking**: Parameters, metrics, timestamps

### 4. **Production-Ready API** âš¡
- **FastAPI backend** with OpenAPI/Swagger documentation
- **Pydantic validation** for request/response schemas
- **Real-time inference** with sub-100ms latency
- **Prometheus instrumentation** for Golden Signals monitoring

### 5. **Interactive Dashboards** ğŸ“ˆ
- **User Dashboard**: Geospatial visualization, cluster analysis, policy simulator
- **Admin Dashboard**: Data management, pipeline triggering, monitoring, version control
- **Real-time updates** from backend API
- **Responsive design** with modern UI/UX

### 6. **Advanced Monitoring** ğŸ‘ï¸
- **Data drift detection** with Evidently AI
- **Performance monitoring** via Prometheus + Grafana
- **Automated alerting** through Alertmanager
- **Infrastructure metrics**: CPU, memory, disk, network

### 7. **CI/CD/CT Pipeline** ğŸš€
- **Continuous Integration**: Automated testing, linting, formatting
- **Continuous Deployment**: Docker build and deployment
- **Continuous Training**: Drift-triggered model retraining
- **Security scanning**: Container vulnerability checks with Trivy

---

## ğŸ“‚ Project Structure

```
devmlops/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci_pipeline.yml          # CI/CD workflow
â”‚       â””â”€â”€ cml_pipeline.yml         # CML reporting
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ main.py                  # FastAPI application
â”‚   â”œâ”€â”€ Dockerfile                   # Backend container
â”‚   â””â”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ User_Dashboard.py        # User interface
â”‚   â”‚   â””â”€â”€ Admin_Dashboard.py       # Admin interface
â”‚   â”œâ”€â”€ Homepage.py                  # Landing page
â”‚   â”œâ”€â”€ indonesia-prov.geojson       # Map data
â”‚   â”œâ”€â”€ Dockerfile                   # Frontend container
â”‚   â””â”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ mage_pipeline/
â”‚   â”œâ”€â”€ project_education/
â”‚   â”‚   â”œâ”€â”€ data_loaders/            # Data ingestion blocks
â”‚   â”‚   â”œâ”€â”€ transformers/            # Data transformation blocks
â”‚   â”‚   â”œâ”€â”€ data_exporters/          # Training and export blocks
â”‚   â”‚   â”œâ”€â”€ custom/                  # Custom blocks (SHAP, viz)
â”‚   â”‚   â”œâ”€â”€ pipelines/               # Pipeline definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ cluster_training_pipeline/
â”‚   â”‚   â”‚   â””â”€â”€ data_seeding/
â”‚   â”‚   â””â”€â”€ io_config.yaml           # Data source configuration
â”‚   â”œâ”€â”€ artifacts/                   # Model artifacts, plots
â”‚   â”œâ”€â”€ data/                        # Raw and processed data
â”‚   â”œâ”€â”€ Dockerfile                   # Mage container
â”‚   â””â”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ mlruns/                          # MLflow tracking storage
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”œâ”€â”€ prometheus.yml           # Prometheus config
â”‚   â”‚   â””â”€â”€ alert_rules.yml          # Alert definitions
â”‚   â”œâ”€â”€ alertmanager/
â”‚   â”‚   â””â”€â”€ config.yml               # Alert routing
â”‚   â””â”€â”€ nginx/
â”‚       â””â”€â”€ nginx.conf               # Artifact server
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_basic.py                # Basic smoke tests
â”‚   â””â”€â”€ test_api.py                  # API endpoint tests
â”œâ”€â”€ .dvc/                            # DVC configuration
â”œâ”€â”€ .pre-commit-config.yaml          # Git hooks
â”œâ”€â”€ docker-compose.yml               # Multi-container orchestration
â”œâ”€â”€ pyproject.toml                   # Python project config
â””â”€â”€ README.md                        # This file
```

---

## ğŸš€ Installation Guide

### Prerequisites

| Requirement | Version | Installation Guide |
|-------------|---------|-------------------|
| Docker Desktop | 20.10+ | [Download](https://www.docker.com/products/docker-desktop) |
| Git | 2.30+ | [Download](https://git-scm.com/downloads) |
| Python | 3.9+ | [Download](https://www.python.org/downloads/) *(Optional for local dev)* |

### Quick Start (5 Minutes)

1. **Clone the Repository**

```bash
git clone https://github.com/rynandasonduty/devmlops.git
cd devmlops
```

2. **Configure Environment Variables**

```bash
cp .env.example .env
# Edit .env with your preferred editor
```

**Key Environment Variables:**

```env
# PostgreSQL Configuration
POSTGRES_USER=mlops_user
POSTGRES_PASSWORD=secure_password_here
POSTGRES_DB=education_db

# MLflow Configuration
MLFLOW_TRACKING_URI=http://mlflow:5000

# Admin Dashboard
ADMIN_PASSWORD=admin123  # Change in production!

# Mage API Trigger (Auto-generated)
TRIGGER_TOKEN=189557234d5e431a972f6d0926b719e9
TRIGGER_SCHEDULE_ID=2
```

3. **Pull Data with DVC** *(Optional if remote storage configured)*

```bash
dvc pull
```

4. **Start All Services**

```bash
docker-compose up --build -d
```

**Expected Output:**
```
âœ… Creating network "devmlops_mlops-net"
âœ… Creating volume "devmlops_postgres_data"
âœ… Creating volume "devmlops_grafana_data"
âœ… Creating volume "devmlops_prometheus_data"
âœ… Creating devmlops_postgres    ... done
âœ… Creating devmlops_mlflow      ... done
âœ… Creating devmlops_mage        ... done
âœ… Creating devmlops_backend     ... done
âœ… Creating devmlops_frontend    ... done
âœ… Creating devmlops_prometheus  ... done
âœ… Creating devmlops_grafana     ... done
```

5. **Verify Services**

```bash
docker-compose ps
```

All services should show status `Up` or `Up (healthy)`.

---

## ğŸ“– Usage Guide

### Service Access URLs

| Service | URL | Description | Credentials |
|---------|-----|-------------|-------------|
| **Streamlit Dashboard** | http://localhost:8501 | Main user interface | None |
| **Admin Dashboard** | http://localhost:8501 â†’ Admin tab | Data management | Password: `admin123` |
| **FastAPI Docs** | http://localhost:8000/docs | Interactive API documentation | None |
| **MLflow UI** | http://localhost:5000 | Experiment tracking | None |
| **Mage AI** | http://localhost:6789 | Pipeline orchestration | None |
| **Prometheus** | http://localhost:9090 | Metrics query interface | None |
| **Grafana** | http://localhost:3000 | Monitoring dashboards | admin/admin |
| **Artifact Server** | http://localhost:8080 | Static file hosting | None |

### ğŸ¬ Complete End-to-End Case Study

This section provides a **detailed step-by-step walkthrough** of the entire MLOps workflow, from data upload to model deployment.

---

## ğŸ“š Case Study: Complete MLOps Workflow

### Scenario
**The Ministry of Education has updated the internet access data for 5 provinces and wants to see how this affects cluster assignments and policy recommendations.**

---

### Phase 1: Data Update (Admin Workflow)

#### Step 1: Prepare Updated CSV File

**Create or modify CSV file with updated data:**

```csv
Provinsi,persen_sekolah_internet_sd,persen_sekolah_internet_smp,persen_sekolah_internet_sma,persen_guru_sertifikasi_sd,persen_guru_sertifikasi_smp,persen_guru_sertifikasi_sma,rasio_siswa_guru_sd,rasio_siswa_guru_smp,rasio_siswa_guru_sma,rasio_siswa_komputer_sd,rasio_siswa_komputer_smp,rasio_siswa_komputer_sma,persen_lulus_akm_literasi,persen_lulus_akm_numerasi,persen_sekolah_listrik_sd,persen_sekolah_listrik_smp,persen_sekolah_listrik_sma,persen_guru_kualifikasi_s1_sd,persen_guru_kualifikasi_s1_smp,persen_guru_kualifikasi_s1_sma
Jawa Timur,95.2,96.8,98.1,45.3,52.1,58.7,15.2,16.8,17.1,650.2,550.1,420.3,72.5,68.9,100.0,100.0,100.0,72.1,82.3,80.5
Papua,52.8,68.5,78.2,22.1,28.3,36.1,17.5,14.2,15.8,1520.3,610.2,480.5,69.73,64.64,58.2,76.8,88.9,42.3,58.2,66.8
...
```

**File Requirements:**
- âœ… Must contain all 20 required columns
- âœ… Province names must match existing records
- âœ… Numeric values must be within valid ranges
- âœ… UTF-8 encoding

#### Step 2: Access Admin Dashboard

```bash
# Open browser
http://localhost:8501
```

**Login Sequence:**
1. Navigate to **"Admin Dashboard"** page (sidebar)
2. Enter password: `admin123`
3. Click **"ğŸ”“ Login"**

![Admin Login](https://img.shields.io/badge/Status-Authenticated-success)

#### Step 3: Upload CSV File

**Navigate to "ğŸ“¥ Data Upload" Tab**

```mermaid
sequenceDiagram
    participant Admin
    participant Frontend
    participant FileSystem
    participant Validator

    Admin->>Frontend: Click "Upload CSV"
    Admin->>Frontend: Select file from computer
    Frontend->>Validator: Validate schema
    Validator->>Validator: Check columns (20 required)
    Validator->>Validator: Check data types
    Validator->>Validator: Check value ranges
    Validator-->>Frontend: Validation results

    alt Validation Success
        Frontend->>Admin: Show âœ… Preview & Stats
        Admin->>Frontend: Click "ğŸ’¾ Save CSV to Server"
        Frontend->>FileSystem: Write to /mage_pipeline/data/raw/
        FileSystem-->>Frontend: File saved successfully
        Frontend->>Frontend: Create version metadata
        Frontend-->>Admin: âœ… File saved (v2)
    else Validation Failed
        Frontend-->>Admin: âŒ Show errors (fix required)
    end
```

**Expected Output:**
```
âœ… File tersimpan di Server (v2)
Path: `/home/src/data/raw/data_kesiapan_pendidikan_final.csv`

ğŸ“Š Quick Stats:
Rows: 38
Cols: 20
âœ… Kolom 'Provinsi' ditemukan
```

#### Step 4: Seed Data to PostgreSQL

**Click "ğŸš€ Update Database (Run Seeding)" Button**

This triggers the **ETL Pipeline** (`data_seeding` pipeline in Mage):

```mermaid
graph LR
    A[CSV File<br/>on Server] --> B[Mage: loaddata.py<br/>Read CSV]
    B --> C[Mage: seeddata.py<br/>PostgreSQL Export]
    C --> D[(PostgreSQL<br/>education_features)]

    style A fill:#f59e0b
    style B fill:#9333ea
    style C fill:#9333ea
    style D fill:#3b82f6
```

**Pipeline Execution Log:**
```
ğŸš€ Menjalankan Pipeline ETL (CSV -> Postgres)...

[Mage Pipeline ID: data_seeding]
âœ… Block: loaddata - Completed (2.3s)
   - Loaded 38 rows, 20 columns
   - Standardized column names
   - Validated required columns

âœ… Block: seeddata - Completed (1.8s)
   - Connected to PostgreSQL
   - Table: education_features
   - Action: REPLACE (old data removed)
   - Inserted: 38 rows

âœ… Pipeline Completed! Run ID: run_20250618_143022
```

**Verification:**
```bash
# Check database manually (optional)
docker-compose exec postgres psql -U mlops_user -d education_db

education_db=# SELECT COUNT(*) FROM education_features;
 count
-------
    38
(1 row)

education_db=# SELECT provinsi, persen_sekolah_internet_smp
               FROM education_features
               WHERE provinsi = 'Papua';
 provinsi | persen_sekolah_internet_smp
----------+-----------------------------
 Papua    |                       68.50
(1 row)
```

---

### Phase 2: Model Training (Automated Pipeline)

#### Step 5: Trigger Training Pipeline

**Navigate to "ğŸš€ Pipeline Control" Tab**

**Configuration Options:**
- **Trigger Reason**: "Updated internet access data for 5 provinces"
- **Pipeline**: `cluster_training_pipeline`
- **Estimated Duration**: 2-5 minutes

**Click "â–¶ï¸ Trigger Pipeline Now"**

```mermaid
graph TD
    A[ğŸš€ Pipeline Start] --> B[Load from PostgreSQL]
    B --> C[Clean Outliers IQR]
    C --> D[Standardize Features]
    D --> E{Data Drift Check<br/>Evidently AI}

    E -->|Drift Score: 0.23<br/>Drift Detected: TRUE| F[Continue Training]
    E -->|No Drift + Model Exists| G[âŒ Stop Pipeline]

    F --> H[Hyperparameter Tuning<br/>Optuna 15 trials]
    H --> I[Train Best Model<br/>K-Means k=3]
    I --> J[Log to MLflow]
    J --> K[Save Artifacts]
    K --> L[Generate Visualizations<br/>Elbow, PCA, Silhouette]
    L --> M[SHAP Analysis]
    M --> N[âœ… Pipeline Complete]

    style E fill:#f59e0b
    style H fill:#3b82f6
    style J fill:#10b981
    style M fill:#a855f7
```

#### Step 6: Monitor Pipeline Execution

**Real-time Progress Logs:**

```
ğŸ“¡ Connecting to Mage API...
âœ… Pipeline Triggered! Run ID: `run_abc123`

â³ Waiting for completion (Timeout: 300s)...

ğŸ”¹ Status: **running** (Time: 5s)
   â””â”€ Block: load_education_features [RUNNING]

ğŸ”¹ Status: **running** (Time: 10s)
   â””â”€ Block: load_education_features [âœ… COMPLETED]
   â””â”€ Block: clean_outliers_iqr [RUNNING]

ğŸ”¹ Status: **running** (Time: 15s)
   â””â”€ Block: clean_outliers_iqr [âœ… COMPLETED]
   â””â”€ Block: transform_standardize [RUNNING]

ğŸ”¹ Status: **running** (Time: 25s)
   â””â”€ Block: transform_standardize [âœ… COMPLETED]
   â””â”€ Block: generate_drift_report [RUNNING]

ğŸ”¹ Status: **running** (Time: 35s)
   â””â”€ Block: generate_drift_report [âœ… COMPLETED]
   â””â”€ âš ï¸ DRIFT DETECTED: Score 0.23 (23% features drifted)
   â””â”€ Block: train_kmeans_clustering [RUNNING]

ğŸ”¹ Status: **running** (Time: 120s)
   â””â”€ Block: train_kmeans_clustering [RUNNING]
   â””â”€ ğŸ”§ Optuna Trial 1/15: k=2, score=0.385
   â””â”€ ğŸ”§ Optuna Trial 2/15: k=3, score=0.452 â­
   â””â”€ ğŸ”§ Optuna Trial 3/15: k=4, score=0.401
   ...
   â””â”€ ğŸ”§ Best: k=3, Silhouette=0.452

ğŸ”¹ Status: **running** (Time: 180s)
   â””â”€ Block: train_kmeans_clustering [âœ… COMPLETED]
   â””â”€ ğŸ“Š Cluster Stats:
       â€¢ Low: 11 provinces (28.9%)
       â€¢ Medium: 16 provinces (42.1%)
       â€¢ High: 11 provinces (28.9%)
   â””â”€ ğŸ’¾ Model saved to MLflow
   â””â”€ Block: generate_visualizations [RUNNING]

ğŸ”¹ Status: **running** (Time: 210s)
   â””â”€ Block: generate_visualizations [âœ… COMPLETED]
   â””â”€ ğŸ“¸ Generated: elbow_method.png
   â””â”€ ğŸ“¸ Generated: silhouette_score.png
   â””â”€ ğŸ“¸ Generated: pca_clusters.png
   â””â”€ Block: explain_model_shap [RUNNING]

ğŸ”¹ Status: **running** (Time: 240s)
   â””â”€ Block: explain_model_shap [âœ… COMPLETED]
   â””â”€ ğŸ“¸ Generated: shap_summary.png
   â””â”€ ğŸ† Top Feature: persen_sekolah_internet_sma (SHAP: 0.342)

âœ… Pipeline Success! Total Duration: 4m 12s

ğŸ‰ Pipeline finished! Data updated.
```

#### Step 7: Verify in MLflow

**Open MLflow UI:** http://localhost:5000

**What to Check:**
1. **Experiments** â†’ `project_education_clustering`
2. **Latest Run**: `KMeans_k3_Final`
3. **Metrics**:
   - `silhouette_score`: 0.452
   - `davies_bouldin_score`: 1.023
   - `inertia`: 1234.56
4. **Parameters**:
   - `n_clusters`: 3
   - `random_state`: 42
5. **Artifacts**:
   - `kmeans_model.pkl`
   - `standard_scaler.pkl`
   - `cluster_metadata.json`

**Screenshot Equivalent:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ MLflow Experiment: project_education_clustering       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Run Name: KMeans_k3_Final                             â•‘
â•‘ Status: FINISHED                                       â•‘
â•‘ Start Time: 2025-12-18 14:35:22                       â•‘
â•‘ Duration: 4m 12s                                       â•‘
â•‘                                                        â•‘
â•‘ ğŸ“Š Metrics:                                            â•‘
â•‘   â€¢ silhouette_score: 0.452                           â•‘
â•‘   â€¢ davies_bouldin_score: 1.023                       â•‘
â•‘   â€¢ inertia: 1234.56                                  â•‘
â•‘   â€¢ combined_score: 0.1452                            â•‘
â•‘                                                        â•‘
â•‘ âš™ï¸ Parameters:                                         â•‘
â•‘   â€¢ n_clusters: 3                                     â•‘
â•‘   â€¢ random_state: 42                                  â•‘
â•‘   â€¢ n_init: 10                                        â•‘
â•‘                                                        â•‘
â•‘ ğŸ“¦ Artifacts:                                          â•‘
â•‘   â€¢ kmeans_model.pkl (1.7 KB)                         â•‘
â•‘   â€¢ standard_scaler.pkl (2.1 KB)                      â•‘
â•‘   â€¢ cluster_metadata.json (3.4 KB)                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

### Phase 3: Monitoring & Drift Detection

#### Step 8: Check Data Drift Report

**Access Drift Report:**
- **Method 1**: Admin Dashboard â†’ **"Monitoring"** Tab
- **Method 2**: Direct file access: http://localhost:8080/data_drift_report.html

**Drift Report Contents:**

```html
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸ“Š EVIDENTLY DATA DRIFT REPORT                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Dataset Drift: DETECTED âš ï¸                                    â•‘
â•‘ Drift Share: 23.5% (5 out of 20 features)                    â•‘
â•‘ Timestamp: 2025-12-18 14:36:45                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                               â•‘
â•‘ ğŸ”´ Drifted Features:                                          â•‘
â•‘   1. persen_sekolah_internet_smp                             â•‘
â•‘      â€¢ Drift Score: 0.87                                     â•‘
â•‘      â€¢ P-value: 0.001 (Kolmogorov-Smirnov test)             â•‘
â•‘      â€¢ Mean Shift: 62.3% â†’ 68.5% (+6.2%)                     â•‘
â•‘                                                               â•‘
â•‘   2. persen_sekolah_internet_sd                              â•‘
â•‘      â€¢ Drift Score: 0.65                                     â•‘
â•‘      â€¢ P-value: 0.023                                        â•‘
â•‘      â€¢ Mean Shift: 56.7% â†’ 61.2% (+4.5%)                     â•‘
â•‘                                                               â•‘
â•‘   ... (3 more features)                                      â•‘
â•‘                                                               â•‘
â•‘ âœ… Stable Features: 15 out of 20                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### Step 9: View Metrics in Prometheus

**Open Prometheus:** http://localhost:9090

**Query Examples:**

```promql
# Data Drift Status (1 = drift, 0 = no drift)
evidently_data_drift_detected

# Drift Score (percentage of drifted features)
evidently_data_drift_score

# API Request Rate
rate(http_requests_total[5m])

# API Error Rate
rate(http_requests_total{status=~"5.."}[5m])
```

**Expected Values:**
```
evidently_data_drift_detected{job="mage_drift_check"} = 1
evidently_data_drift_score{job="mage_drift_check"} = 0.235
```

#### Step 10: View Dashboard in Grafana

**Open Grafana:** http://localhost:3000
**Login:** admin / admin

**Pre-configured Dashboards:**

1. **MLOps System Overview**
   - API request rate (RPS)
   - API latency (p50, p95, p99)
   - Error rate (%)
   - Model inference count

2. **Data Drift Monitoring**
   - Drift score over time (line chart)
   - Drift detection events (annotations)
   - Feature drift breakdown (bar chart)

3. **Infrastructure Health**
   - CPU usage per container
   - Memory consumption
   - Disk I/O
   - Network throughput

**Sample Dashboard View:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“ˆ MLOps System Overview               ğŸ”„ Last 1h         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                            â•‘
â•‘  API Request Rate:  â–â–‚â–ƒâ–…â–‡â–ˆâ–‡â–…â–ƒâ–‚â–  125 req/min             â•‘
â•‘  Avg Latency:       â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–  45ms (p95: 87ms)        â•‘
â•‘  Error Rate:        â–â–â–â–â–â–â–â–â–â–â–  0.02%                    â•‘
â•‘                                                            â•‘
â•‘  ğŸ“Š Data Drift Score:                                      â•‘
â•‘  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.235 (23.5%)                       â•‘
â•‘                                                            â•‘
â•‘  ğŸ¯ Model Performance:                                     â•‘
â•‘  â€¢ Inferences Today: 1,247                                â•‘
â•‘  â€¢ Avg Prediction Time: 12ms                              â•‘
â•‘  â€¢ Cache Hit Rate: 67%                                    â•‘
â•‘                                                            â•‘
â•‘  âš ï¸ Recent Alert:                                          â•‘
â•‘  [14:36] Data Drift Detected â†’ Training Triggered         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

### Phase 4: User Dashboard Visualization

#### Step 11: View Updated Predictions (User Dashboard)

**Navigate to User Dashboard:** http://localhost:8501 â†’ **User Dashboard**

**What's New After Training:**
- âœ… Map shows updated cluster colors
- âœ… Statistics reflect new distribution
- âœ… Papua moved from "Low" â†’ "Medium" cluster (due to internet improvement)

**Interactive Map Updates:**

```
Before Update:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Papua: ğŸ”´ Rendah (Low)              â”‚
â”‚ â€¢ Internet SMP: 63.04%              â”‚
â”‚ â€¢ Cluster Score: 32.1               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After Update:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Papua: ğŸŸ¡ Sedang (Medium)           â”‚
â”‚ â€¢ Internet SMP: 68.50% (+5.46%)    â”‚
â”‚ â€¢ Cluster Score: 58.7 (+26.6)      â”‚
â”‚ â€¢ Status: â¬†ï¸ UPGRADED               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Step 12: Feature Engineering Experiment (User Dashboard)

**Navigate to "8.1 Live Inference Playground"**

**Scenario**: Test how changing infrastructure affects cluster assignment

**Adjust Sliders:**
```
Infrastructure Settings:
â”œâ”€ Internet SD: [85%] â—â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ Internet SMP: [90%] â”€â”€â—â”€â”€â”€â”€â”€â”€â”€
â””â”€ Internet SMA: [95%] â”€â”€â”€â”€â—â”€â”€â”€â”€â”€

Teacher Quality:
â”œâ”€ Certified SD: [45%] â—â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ Certified SMP: [50%] â”€â”€â—â”€â”€â”€â”€â”€â”€â”€
â””â”€ Certified SMA: [60%] â”€â”€â”€â”€â—â”€â”€â”€â”€â”€

Technology Access:
â”œâ”€ PC Ratio SD: [25.0] â—â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ PC Ratio SMP: [20.0] â”€â”€â—â”€â”€â”€â”€â”€â”€â”€
â””â”€ PC Ratio SMA: [15.0] â”€â”€â”€â”€â—â”€â”€â”€â”€â”€

Student Outcomes:
â”œâ”€ Literacy: [65%] â”€â”€â”€â”€â—â”€â”€â”€â”€â”€
â””â”€ Numeracy: [60%] â”€â”€â”€â—â”€â”€â”€â”€â”€â”€
```

**Click "âš¡ Prediksi Klaster"**

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API
    participant Model
    participant Scaler

    User->>Frontend: Adjust feature values
    User->>Frontend: Click "Prediksi"
    Frontend->>API: POST /predict with JSON payload
    API->>Scaler: Transform input (StandardScaler)
    Scaler-->>API: Scaled features
    API->>Model: Predict cluster (K-Means)
    Model-->>API: Cluster ID: 2
    API->>API: Map ID to label
    API-->>Frontend: {"cluster_id": 2, "label": "Tinggi (High)"}
    Frontend->>Frontend: Render result with styling
    Frontend-->>User: Display prediction
```

**API Request (under the hood):**
```json
POST http://localhost:8000/predict
Content-Type: application/json

{
  "persen_sekolah_internet_sd": 85.0,
  "persen_sekolah_internet_smp": 90.0,
  "persen_sekolah_internet_sma": 95.0,
  "persen_guru_sertifikasi_sd": 45.0,
  "persen_guru_sertifikasi_smp": 50.0,
  "persen_guru_sertifikasi_sma": 60.0,
  "rasio_siswa_guru_sd": 18.0,
  "rasio_siswa_guru_smp": 16.0,
  "rasio_siswa_guru_sma": 15.0,
  "rasio_siswa_komputer_sd": 25.0,
  "rasio_siswa_komputer_smp": 20.0,
  "rasio_siswa_komputer_sma": 15.0,
  "persen_lulus_akm_literasi": 65.0,
  "persen_lulus_akm_numerasi": 60.0,
  "persen_sekolah_listrik_sd": 98.0,
  "persen_sekolah_listrik_smp": 99.0,
  "persen_sekolah_listrik_sma": 100.0,
  "persen_guru_kualifikasi_s1_sd": 80.0,
  "persen_guru_kualifikasi_s1_smp": 85.0,
  "persen_guru_kualifikasi_s1_sma": 90.0
}
```

**API Response:**
```json
{
  "cluster_id": 2,
  "label": "Tinggi (High Readiness)",
  "message": "Prediksi berhasil"
}
```

**Frontend Display:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸ“Š Prediction Result                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                            â•‘
â•‘          ğŸŸ¢ Tinggi (High Readiness)        â•‘
â•‘              Cluster ID: 2                 â•‘
â•‘                                            â•‘
â•‘  âœ… Prediksi Berhasil!                     â•‘
â•‘                                            â•‘
â•‘  ğŸ“‹ Details:                               â•‘
â•‘  {                                         â•‘
â•‘    "cluster_id": 2,                        â•‘
â•‘    "label": "Tinggi (High Readiness)",    â•‘
â•‘    "message": "Prediksi berhasil"         â•‘
â•‘  }                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

### Phase 5: Advanced Analytics & Visualization

#### Step 13: Explore SHAP Explanations

**Navigate to: User Dashboard â†’ Tab "ğŸ§  SHAP Explainability"**

**SHAP Summary Plot** (generated during training):

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸ§  SHAP Feature Importance Summary                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                               â•‘
â•‘  persen_sekolah_internet_sma    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  0.342     â•‘
â•‘  persen_guru_sertifikasi_smp    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘  0.287     â•‘
â•‘  rasio_siswa_komputer_sd        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  0.234     â•‘
â•‘  persen_lulus_akm_numerasi      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.198     â•‘
â•‘  persen_guru_kualifikasi_s1_sma â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.176     â•‘
â•‘  persen_sekolah_listrik_sma     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.154     â•‘
â•‘  rasio_siswa_guru_smp           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.132     â•‘
â•‘  persen_sekolah_internet_smp    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.118     â•‘
â•‘  ...                                                          â•‘
â•‘                                                               â•‘
â•‘  ğŸ” Interpretation:                                           â•‘
â•‘  â€¢ High school internet access is the strongest predictor    â•‘
â•‘  â€¢ Teacher certification at middle school level is critical  â•‘
â•‘  â€¢ Technology access (PC ratios) directly impacts readiness  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**How SHAP Works:**
```python
# Code snippet from explain_model_shap.py
explainer = shap.KernelExplainer(model.predict, X)
shap_values = explainer.shap_values(X)
shap.summary_plot(shap_values, X, plot_type="bar", show=False)
```

#### Step 14: View Hyperparameter Tuning Process (Optuna)

**Navigate to: Admin Dashboard â†’ "Monitoring" â†’ View Logs**

**Optuna Trial History:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         ğŸ”§ OPTUNA HYPERPARAMETER OPTIMIZATION                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Study Name: kmeans_optimization                               â•‘
â•‘ Direction: Maximize (combined_score)                          â•‘
â•‘ N Trials: 15                                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                â•‘
â•‘ Trial #1  â”‚ k=2 â”‚ Sil: 0.385 â”‚ DB: 1.234 â”‚ Score: 0.0143     â•‘
â•‘ Trial #2  â”‚ k=3 â”‚ Sil: 0.452 â”‚ DB: 1.023 â”‚ Score: 0.1452 â­  â•‘
â•‘ Trial #3  â”‚ k=4 â”‚ Sil: 0.401 â”‚ DB: 1.157 â”‚ Score: 0.0542     â•‘
â•‘ Trial #4  â”‚ k=5 â”‚ Sil: 0.368 â”‚ DB: 1.301 â”‚ Score: -0.0226    â•‘
â•‘ Trial #5  â”‚ k=6 â”‚ Sil: 0.323 â”‚ DB: 1.412 â”‚ Score: -0.0713    â•‘
â•‘ Trial #6  â”‚ k=2 â”‚ Sil: 0.382 â”‚ DB: 1.245 â”‚ Score: 0.0085     â•‘
â•‘ Trial #7  â”‚ k=3 â”‚ Sil: 0.448 â”‚ DB: 1.045 â”‚ Score: 0.1345     â•‘
â•‘ Trial #8  â”‚ k=4 â”‚ Sil: 0.395 â”‚ DB: 1.178 â”‚ Score: 0.0416     â•‘
â•‘ ...                                                            â•‘
â•‘ Trial #15 â”‚ k=3 â”‚ Sil: 0.445 â”‚ DB: 1.067 â”‚ Score: 0.1249     â•‘
â•‘                                                                â•‘
â•‘ âœ… Best Trial: #2                                              â•‘
â•‘    â€¢ n_clusters: 3                                            â•‘
â•‘    â€¢ Silhouette Score: 0.452                                  â•‘
â•‘    â€¢ Davies-Bouldin: 1.023                                    â•‘
â•‘    â€¢ Combined Score: 0.1452                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Optuna Optimization Code:**
```python
# From train_kmeans_clustering.py
def objective(trial, X):
    n_clusters = trial.suggest_int("n_clusters", 2, 6)
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X)

    sil_score = silhouette_score(X, labels)
    db_score = davies_bouldin_score(X, labels)

    # Combined metric: prioritize silhouette, penalize high DB
    combined_score = sil_score - (0.3 * db_score)
    return combined_score

# Run optimization
study = optuna.create_study(direction="maximize")
study.optimize(lambda trial: objective(trial, X), n_trials=15)
```

---

### Phase 6: Security & Code Quality Verification

#### Step 15: View Security Scan Results (Trivy + Bandit)

**Trivy Container Scanning** (runs in CI pipeline):

```bash
# View scan results from GitHub Actions
# Or run locally:
docker build -t mlops-backend:test ./backend
trivy image mlops-backend:test
```

**Sample Trivy Output:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ” TRIVY VULNERABILITY SCAN REPORT                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Image: mlops-backend:test                                  â•‘
â•‘ Scan Date: 2025-12-18 15:00:00                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                            â•‘
â•‘ âœ… Total Vulnerabilities: 3                                â•‘
â•‘    â€¢ CRITICAL: 0                                           â•‘
â•‘    â€¢ HIGH: 0                                               â•‘
â•‘    â€¢ MEDIUM: 2                                             â•‘
â•‘    â€¢ LOW: 1                                                â•‘
â•‘                                                            â•‘
â•‘ ğŸ“¦ Python Package Vulnerabilities:                        â•‘
â•‘   [MEDIUM] CVE-2024-XXXX                                  â•‘
â•‘   Package: requests (2.28.0)                              â•‘
â•‘   Fixed: 2.31.0                                           â•‘
â•‘   Impact: Potential SSL verification bypass              â•‘
â•‘                                                            â•‘
â•‘ âœ… BUILD PASSED: No CRITICAL/HIGH vulnerabilities         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Bandit Security Scanning** (runs in CI pipeline):

```bash
# View scan results from GitHub Actions
# Or run locally:
bandit -r backend/ mage_pipeline/ -ll -ii
```

**Sample Bandit Output:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ›¡ï¸ BANDIT SECURITY SCAN REPORT                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Scan Path: backend/, mage_pipeline/                       â•‘
â•‘ Severity Level: Low, Medium, High                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                            â•‘
â•‘ âœ… Code Scanned: 1,247 lines                              â•‘
â•‘ âš ï¸ Issues Found: 0 High, 0 Medium, 2 Low                  â•‘
â•‘                                                            â•‘
â•‘ Low Severity Issues:                                       â•‘
â•‘   [B608:hardcoded_sql_expressions]                        â•‘
â•‘   File: data_loaders/load_features.py:15                  â•‘
â•‘   Issue: SQL statement with parameterized query           â•‘
â•‘   Status: âœ… Mitigated (using SQLAlchemy ORM)             â•‘
â•‘                                                            â•‘
â•‘ âœ… SECURITY CHECK PASSED                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Where These Tools Run:**

```mermaid
graph LR
    A[Developer Push Code] --> B[GitHub Actions CI]
    B --> C[Ruff Linting]
    B --> D[Black Formatting]
    B --> E[Bandit Security Scan]
    C --> F{All Passed?}
    D --> F
    E --> F
    F -->|Yes| G[Build Docker Images]
    G --> H[Trivy Vulnerability Scan]
    H --> I{Critical CVEs?}
    I -->|No| J[âœ… CI Passed]
    I -->|Yes| K[âŒ CI Failed - Fix Required]
    F -->|No| K
```

---

### Phase 7: Complete Workflow Verification

#### Step 16: End-to-End Verification Checklist

Use this checklist to verify the complete MLOps pipeline:

**Data Flow Verification:**
```
âœ… 1. CSV uploaded and validated
âœ… 2. File saved to /mage_pipeline/data/raw/
âœ… 3. PostgreSQL table updated (38 rows)
âœ… 4. Training pipeline triggered
âœ… 5. Data drift detected (23.5%)
âœ… 6. Optuna found optimal k=3
âœ… 7. Model logged to MLflow
âœ… 8. Artifacts generated (SHAP, PCA, Elbow)
âœ… 9. Metrics pushed to Prometheus
âœ… 10. Grafana dashboard updated
âœ… 11. Backend API loaded new model
âœ… 12. User Dashboard shows new predictions
```

**Monitoring Verification:**
```
âœ… Prometheus scraping metrics (5s interval)
âœ… Grafana displaying dashboards
âœ… Evidently drift report accessible
âœ… Email alert received (if drift threshold exceeded)
âœ… MLflow tracking UI accessible
âœ… Artifact server serving files
```

**API Verification:**
```bash
# Health check
curl http://localhost:8000/
# Response: {"status": "active", "model_status": "Loaded"}

# Prediction test
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"persen_sekolah_internet_sd": 85, ...}'
# Response: {"cluster_id": 2, "label": "Tinggi (High Readiness)", ...}

# Metrics endpoint
curl http://localhost:8000/metrics
# Response: Prometheus metrics in text format
```

---

## ğŸ”¬ Advanced Features Explained

### 1. **SHAP (SHapley Additive exPlanations)**

**Purpose**: Explain model predictions and identify feature importance

**Implementation**:
```python
# Location: mage_pipeline/project_education/custom/explain_model_shap.py

import shap
import matplotlib.pyplot as plt

# Create explainer
explainer = shap.KernelExplainer(model.predict, X)

# Calculate SHAP values for all samples
shap_values = explainer.shap_values(X)

# Generate summary plot (bar chart)
shap.summary_plot(shap_values, X, plot_type="bar", show=False)
plt.savefig("/home/src/artifacts/shap_summary.png")
```

**Key Benefits**:
- âœ… Identifies which features most influence cluster assignments
- âœ… Provides model-agnostic explanations
- âœ… Helps stakeholders understand "why" a province is in a certain cluster
- âœ… Enables data-driven policy decisions

**Example Output Interpretation**:
```
Feature: persen_sekolah_internet_sma | SHAP: 0.342
â†’ High school internet access is the #1 driver of cluster assignment
â†’ Provinces with >90% internet access â†’ High Readiness cluster
â†’ Provinces with <60% internet access â†’ Low Readiness cluster
```

---

### 2. **Optuna (Hyperparameter Optimization)**

**Purpose**: Automatically find the best number of clusters (k) for K-Means

**Implementation**:
```python
# Location: mage_pipeline/project_education/data_exporters/train_kmeans_clustering.py

import optuna
from sklearn.metrics import silhouette_score, davies_bouldin_score

def objective(trial, X):
    # Suggest k value between 2 and 6
    n_clusters = trial.suggest_int("n_clusters", 2, 6)

    # Train K-Means
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X)

    # Calculate metrics
    sil_score = silhouette_score(X, labels)
    db_score = davies_bouldin_score(X, labels)

    # Combined objective: maximize silhouette, minimize Davies-Bouldin
    combined_score = sil_score - (0.3 * db_score)
    return combined_score

# Create study and optimize
study = optuna.create_study(direction="maximize")
study.optimize(lambda trial: objective(trial, X), n_trials=15)

# Get best parameters
best_k = study.best_params["n_clusters"]
print(f"âœ… Best k={best_k}, Score={study.best_value:.4f}")
```

**Key Benefits**:
- âœ… Removes manual trial-and-error for choosing k
- âœ… Evaluates multiple metrics simultaneously
- âœ… Provides statistical confidence in cluster count
- âœ… Reproducible optimization process

**Optimization Strategy**:
```
Metric Formula: Combined Score = Silhouette - (0.3 Ã— Davies-Bouldin)

Why this formula?
â€¢ Silhouette Score (0 to 1): Higher = better separation
â€¢ Davies-Bouldin Index (0 to âˆ): Lower = tighter clusters
â€¢ Weight 0.3: Balances between separation and compactness
```

---

### 3. **Trivy (Container Security Scanner)**

**Purpose**: Detect security vulnerabilities in Docker images before deployment

**Implementation**:
```yaml
# Location: .github/workflows/ci_pipeline.yml

container-security:
  runs-on: ubuntu-latest
  steps:
    - name: Build Backend Image
      run: docker build -t mlops-backend:test ./backend

    - name: Run Trivy Vulnerability Scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'mlops-backend:test'
        format: 'table'
        exit-code: '1'           # Fail CI if critical CVEs found
        ignore-unfixed: true     # Ignore vulnerabilities without fixes
        vuln-type: 'os,library'  # Scan OS and library vulnerabilities
        severity: 'CRITICAL,HIGH'
```

**What Trivy Scans**:
- ğŸ” Base image vulnerabilities (e.g., Python 3.9 slim)
- ğŸ” Python package CVEs (e.g., outdated `requests`, `urllib3`)
- ğŸ” OS-level vulnerabilities (e.g., `apt` packages)

**Example Scan Results**:
```
python:3.9-slim (debian 11.6)
==================================
Total: 5 (CRITICAL: 0, HIGH: 2, MEDIUM: 3)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Library    â”‚ Vulnerabilityâ”‚ Severity â”‚ Installedâ”‚ Fixed Version       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ openssl     â”‚ CVE-2024-XXX â”‚ HIGH     â”‚ 1.1.1n   â”‚ 1.1.1w              â”‚
â”‚ urllib3     â”‚ CVE-2024-YYY â”‚ HIGH     â”‚ 1.26.15  â”‚ 2.0.7               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Benefits**:
- âœ… Prevents deploying vulnerable containers
- âœ… Automated security checks in CI pipeline
- âœ… Provides actionable fix recommendations
- âœ… Compliance with security best practices

---

### 4. **Bandit (Python Security Linter)**

**Purpose**: Identify common security issues in Python code

**Implementation**:
```yaml
# Location: .github/workflows/ci_pipeline.yml

- name: Security Scan with Bandit
  run: |
    bandit -r backend/ mage_pipeline/ -ll -ii
```

**What Bandit Detects**:

| Issue Code | Severity | Description |
|------------|----------|-------------|
| **B201** | HIGH | Flask app run with debug=True in production |
| **B608** | MEDIUM | SQL injection via string concatenation |
| **B105** | LOW | Hardcoded password in source code |
| **B601** | MEDIUM | Shell injection via os.system() |
| **B404** | LOW | Import of subprocess module (potential risk) |

**Example Detection**:
```python
# âŒ INSECURE CODE (Bandit would flag this)
password = "admin123"  # B105: Hardcoded password
query = f"SELECT * FROM users WHERE name = '{user_input}'"  # B608: SQL injection

# âœ… SECURE CODE (Bandit approves)
password = os.getenv("DB_PASSWORD")
query = "SELECT * FROM users WHERE name = %s"
cursor.execute(query, (user_input,))
```

**Key Benefits**:
- âœ… Catches security issues during development
- âœ… Prevents SQL injection, XSS, and other vulnerabilities
- âœ… Enforces secure coding practices
- âœ… Integrated into pre-commit hooks and CI

---

### 5. **Evidently AI (Data Drift Detection)**

**Purpose**: Monitor data quality and detect distribution changes over time

**Implementation**:
```python
# Location: mage_pipeline/project_education/data_exporters/generate_drift_report.py

from evidently.report import Report
from evidently.metric_preset import DataDriftPreset, DataQualityPreset

# Split data: reference (old) vs current (new)
reference_data = df.iloc[:mid_point]
current_data = df.iloc[mid_point:]

# Generate report
report = Report(metrics=[DataDriftPreset(), DataQualityPreset()])
report.run(reference_data=reference_data, current_data=current_data)

# Save HTML report
report.save_html("/home/src/artifacts/data_drift_report.html")

# Extract drift metrics
result = report.as_dict()
drift_share = result["metrics"][0]["result"]["drift_share"]
dataset_drift = result["metrics"][0]["result"]["dataset_drift"]

print(f"ğŸ“Š Drift Score: {drift_share:.4f}")
print(f"âš ï¸ Drift Detected: {dataset_drift}")
```

**Drift Detection Logic**:
```mermaid
graph TD
    A[New Data Arrives] --> B[Calculate Feature Statistics]
    B --> C{Kolmogorov-Smirnov Test<br/>per Feature}
    C -->|p-value < 0.05| D[Feature Drifted]
    C -->|p-value >= 0.05| E[Feature Stable]
    D --> F[Count Drifted Features]
    E --> F
    F --> G{Drift Share > 15%?}
    G -->|Yes| H[ğŸš¨ Trigger Retraining]
    G -->|No| I[âœ… Skip Retraining]
```

**Key Benefits**:
- âœ… Detects when model becomes stale
- âœ… Prevents silent model degradation
- âœ… Triggers automatic retraining (Continuous Training)
- âœ… Provides visual drift reports for stakeholders

**Example Drift Scenario**:
```
Scenario: Government internet subsidy program launched
â†’ 5 provinces increase internet access by 20%+
â†’ Evidently detects drift in "internet_smp" feature
â†’ Drift score: 0.23 (23% of features drifted)
â†’ System automatically triggers retraining
â†’ New model adapts to changed data distribution
```

---

### 6. **Prometheus & Grafana (Observability Stack)**

**Purpose**: Monitor system health and model performance in real-time

**Prometheus Configuration**:
```yaml
# Location: monitoring/prometheus/prometheus.yml

scrape_configs:
  - job_name: 'backend-api'
    scrape_interval: 5s  # Scrape every 5 seconds
    static_configs:
      - targets: ['backend:8000']

  - job_name: 'pushgateway'
    static_configs:
      - targets: ['pushgateway:9091']  # Drift metrics from Mage
```

**FastAPI Metrics Instrumentation**:
```python
# Location: backend/app/main.py

from prometheus_fastapi_instrumentator import Instrumentator

app = FastAPI(title="Education Cluster API")

# Auto-instrument with Prometheus
Instrumentator().instrument(app).expose(app)

# This automatically provides:
# â€¢ http_requests_total
# â€¢ http_request_duration_seconds
# â€¢ http_requests_inprogress
```

**Custom Metrics (Drift Score)**:
```python
# Location: mage_pipeline/project_education/data_exporters/generate_drift_report.py

from prometheus_client import CollectorRegistry, Gauge, push_to_gateway

registry = CollectorRegistry()

# Define metrics
g_drift_score = Gauge('evidently_data_drift_score', 'Share of drifting features', registry=registry)
g_drift_status = Gauge('evidently_data_drift_detected', '1 if drift, 0 otherwise', registry=registry)

# Set values
g_drift_score.set(0.235)  # 23.5% features drifted
g_drift_status.set(1)      # Drift detected

# Push to Pushgateway â†’ Prometheus scrapes from there
push_to_gateway('pushgateway:9091', job='mage_drift_check', registry=registry)
```

**Grafana Dashboard Panels**:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Panel 1: API Request Rate (Time Series)                  â•‘
â•‘  Query: rate(http_requests_total[5m])                     â•‘
â•‘  Visualization: Line chart                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Panel 2: API Latency (Histogram)                         â•‘
â•‘  Query: histogram_quantile(0.95,                          â•‘
â•‘          http_request_duration_seconds_bucket)            â•‘
â•‘  Visualization: Gauge (p95 latency)                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Panel 3: Data Drift Score (Time Series)                  â•‘
â•‘  Query: evidently_data_drift_score                        â•‘
â•‘  Visualization: Line chart with threshold line at 0.15    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Panel 4: Model Inference Count (Counter)                 â•‘
â•‘  Query: increase(http_requests_total{path="/predict"}[1h])â•‘
â•‘  Visualization: Stat panel                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Key Benefits**:
- âœ… Real-time visibility into system health
- âœ… Automated alerting on anomalies
- âœ… Historical trend analysis
- âœ… Proactive incident detection

---

## ğŸ”„ Complete Workflow Diagram (All Tools Integrated)

```mermaid
flowchart TD
    A[Admin Uploads CSV] --> B[File Validation]
    B --> C[Save to Server]
    C --> D[Trigger ETL Pipeline<br/>Mage: data_seeding]
    D --> E[(PostgreSQL<br/>Updated)]

    E --> F[Trigger Training Pipeline<br/>Mage: cluster_training]
    F --> G[Load Data]
    G --> H[Clean Outliers]
    H --> I[Standardize Features]
    I --> J{Evidently AI<br/>Drift Check}

    J -->|Drift Detected| K[Optuna<br/>Hyperparameter Tuning]
    J -->|No Drift + Model Exists| L[âŒ Stop Pipeline]

    K --> M[Train K-Means<br/>k=2,3,4,5,6]
    M --> N[Select Best Model<br/>k=3]
    N --> O[SHAP Analysis<br/>Feature Importance]
    O --> P[Log to MLflow<br/>Model Registry]

    P --> Q[Push Metrics to<br/>Prometheus via Pushgateway]
    Q --> R[Grafana Dashboards<br/>Update]

    P --> S[Backend API<br/>Load New Model]
    S --> T[User Dashboard<br/>Shows New Predictions]

    T --> U[User Adjusts Features]
    U --> V[API Prediction<br/>POST /predict]
    V --> W[Return Cluster Label]

    style J fill:#f59e0b
    style K fill:#3b82f6
    style O fill:#a855f7
    style P fill:#10b981
    style Q fill:#ef4444
```

---

## ğŸ“Š Metrics & KPIs Tracking

### Model Performance Metrics

| Metric | Current Value | Target | Status |
|--------|---------------|--------|--------|
| **Silhouette Score** | 0.452 | > 0.40 | âœ… GOOD |
| **Davies-Bouldin Index** | 1.023 | < 1.50 | âœ… GOOD |
| **Inertia** | 1,234.56 | - | - |
| **Training Time** | 4m 12s | < 10m | âœ… GOOD |

### System Performance Metrics

| Metric | Current Value | Target | Status |
|--------|---------------|--------|--------|
| **API Latency (p95)** | 87ms | < 200ms | âœ… GOOD |
| **API Error Rate** | 0.02% | < 1% | âœ… GOOD |
| **Throughput** | 125 req/min | > 50 req/min | âœ… GOOD |
| **Model Load Time** | 1.2s | < 3s | âœ… GOOD |

### Data Quality Metrics

| Metric | Current Value | Target | Status |
|--------|---------------|--------|--------|
| **Data Drift Score** | 0.235 | < 0.30 | âœ… ACCEPTABLE |
| **Missing Data %** | 0% | < 5% | âœ… EXCELLENT |
| **Outliers Removed** | 2.1% | - | - |
| **Feature Correlation** | Max 0.78 | < 0.95 | âœ… GOOD |

---

## ğŸ“ Learning Resources

### Understanding the Tools

| Tool | Best For | Learning Path |
|------|----------|---------------|
| **Mage AI** | ETL orchestration | [Official Docs](https://docs.mage.ai/) â†’ Build first pipeline â†’ Explore triggers |
| **MLflow** | Experiment tracking | [MLflow Tutorial](https://mlflow.org/docs/latest/tutorials-and-examples/) â†’ Log first experiment â†’ Model registry |
| **Optuna** | Hyperparameter tuning | [Optuna Examples](https://github.com/optuna/optuna-examples) â†’ Optimize scikit-learn â†’ Visualize studies |
| **SHAP** | Model explainability | [SHAP GitHub](https://github.com/slundberg/shap) â†’ Understand TreeExplainer â†’ KernelExplainer for any model |
| **Evidently** | Drift detection | [Evidently Docs](https://docs.evidentlyai.com/) â†’ Generate first report â†’ Integrate with monitoring |
| **Prometheus** | Metrics collection | [Prometheus Basics](https://prometheus.io/docs/introduction/first_steps/) â†’ Write PromQL queries â†’ Set up alerts |
| **Trivy** | Container security | [Trivy Docs](https://aquasecurity.github.io/trivy/) â†’ Scan first image â†’ Integrate CI/CD |
| **Bandit** | Code security | [Bandit GitHub](https://github.com/PyCQA/bandit) â†’ Run first scan â†’ Fix issues â†’ Pre-commit integration |

---

## ğŸ“ Summary

### âœ… What This Documentation Covers

This comprehensive documentation provides:

1. **âœ… Complete Installation Guide**
   - Step-by-step setup from zero to running system
   - Docker Compose configuration
   - Environment variables explained
   - Service verification steps

2. **âœ… End-to-End Case Study**
   - Admin uploads CSV file â†’ Validation â†’ Storage
   - ETL pipeline execution â†’ PostgreSQL update
   - Training pipeline trigger â†’ Drift detection
   - Model training with Optuna â†’ MLflow logging
   - SHAP analysis â†’ Visualization generation
   - Metrics to Prometheus â†’ Grafana dashboards
   - User dashboard updates â†’ API predictions

3. **âœ… All Tools Explained**
   - **SHAP**: Feature importance and model explainability
   - **Optuna**: Automatic hyperparameter optimization (k=2-6)
   - **Trivy**: Container vulnerability scanning
   - **Bandit**: Python code security analysis
   - **Evidently AI**: Data drift detection and monitoring
   - **Prometheus**: Metrics collection and alerting
   - **Grafana**: Visualization and dashboards
   - **MLflow**: Experiment tracking and model registry
   - **Mage AI**: Pipeline orchestration
   - **DVC**: Data version control

4. **âœ… Complete Workflows**
   - Data upload â†’ ETL â†’ Training â†’ Deployment
   - Monitoring â†’ Drift detection â†’ Retraining
   - User interaction â†’ API â†’ Prediction
   - CI/CD â†’ Security scanning â†’ Container deployment

---

## ğŸ¯ Quick Reference: Common Tasks

### Daily Operations

| Task | Command/Action | Duration |
|------|----------------|----------|
| **Start System** | `docker-compose up -d` | 2-3 min |
| **Stop System** | `docker-compose down` | 30 sec |
| **View Logs** | `docker-compose logs -f [service]` | Real-time |
| **Check Status** | `docker-compose ps` | Instant |
| **Restart Service** | `docker-compose restart [service]` | 10-30 sec |

### Admin Tasks

| Task | Location | Estimated Time |
|------|----------|----------------|
| **Upload New Data** | Admin Dashboard â†’ Data Upload | 2 min |
| **Trigger Training** | Admin Dashboard â†’ Pipeline Control | 4-5 min |
| **View Drift Report** | Admin Dashboard â†’ Monitoring | Instant |
| **Check Logs** | Admin Dashboard â†’ Monitoring â†’ Logs | Instant |
| **Version Rollback** | Admin Dashboard â†’ Version History | 1 min |

### User Tasks

| Task | Location | Estimated Time |
|------|----------|----------------|
| **View Cluster Map** | User Dashboard â†’ Homepage | Instant |
| **Test Predictions** | User Dashboard â†’ Live Inference | 5 sec |
| **Policy Simulator** | User Dashboard â†’ Section 6 | 1-2 min |
| **View Analytics** | User Dashboard â†’ Multiple Tabs | 2-5 min |

---

## ğŸ” Security Best Practices

### Production Deployment Checklist

```
Before deploying to production, ensure:

ğŸ” Credentials:
  âœ… Change default admin password (admin123)
  âœ… Use strong PostgreSQL password
  âœ… Rotate API tokens/keys
  âœ… Enable HTTPS/TLS for all services
  âœ… Use secrets management (e.g., AWS Secrets Manager)

ğŸ›¡ï¸ Security Scanning:
  âœ… Trivy scan passes (no CRITICAL vulnerabilities)
  âœ… Bandit scan passes (no HIGH issues)
  âœ… Dependency vulnerabilities addressed
  âœ… Container images from trusted sources

ğŸ”’ Access Control:
  âœ… Enable authentication for Grafana
  âœ… Enable authentication for MLflow
  âœ… Enable authentication for Mage AI
  âœ… Restrict database access (firewall rules)
  âœ… Use API rate limiting

ğŸŒ Network Security:
  âœ… Use reverse proxy (Nginx/Traefik)
  âœ… Enable CORS correctly in FastAPI
  âœ… Use private Docker networks
  âœ… Implement IP whitelisting

ğŸ“Š Monitoring:
  âœ… Set up alerting (email/Slack)
  âœ… Configure log aggregation
  âœ… Enable audit logging
  âœ… Monitor for anomalies
```

---

## ğŸ› Common Pitfalls & Solutions

### Issue: Model Not Loading After Training

**Symptom**: API returns "Model belum siap"

**Solution**:
```bash
# 1. Check if artifacts exist
docker-compose exec backend ls -la /app/artifacts/

# 2. Verify model file
docker-compose exec backend cat /app/artifacts/cluster_metadata.json

# 3. Check backend logs
docker-compose logs backend | grep -i "model"

# 4. Restart backend to reload
docker-compose restart backend
```

### Issue: Drift Detection Always Triggers

**Symptom**: Every run triggers retraining even with stable data

**Solution**:
```python
# Adjust drift threshold in generate_drift_report.py
DRIFT_THRESHOLD = 0.30  # Increase from 0.15 to 0.30
dataset_drift = drift_share > DRIFT_THRESHOLD
```

### Issue: Grafana Shows "No Data"

**Symptom**: Prometheus metrics not appearing in Grafana

**Solution**:
```bash
# 1. Check Prometheus targets
curl http://localhost:9090/api/v1/targets | jq

# 2. Verify backend is exposing metrics
curl http://localhost:8000/metrics

# 3. Check Prometheus config
docker-compose exec prometheus cat /etc/prometheus/prometheus.yml

# 4. Restart Prometheus
docker-compose restart prometheus
```

---

## ğŸ“ˆ Scaling Considerations

### Horizontal Scaling

**Backend API** (FastAPI):
```yaml
# docker-compose.yml
backend:
  deploy:
    replicas: 3  # Run 3 instances
  environment:
    - WORKERS=4  # 4 Uvicorn workers per instance
```

**Load Balancer** (Nginx):
```nginx
upstream backend {
    server backend_1:8000;
    server backend_2:8000;
    server backend_3:8000;
}
```

### Vertical Scaling

**Increase Container Resources**:
```yaml
backend:
  deploy:
    resources:
      limits:
        cpus: '2.0'
        memory: 4G
      reservations:
        cpus: '1.0'
        memory: 2G
```

### Database Scaling

**PostgreSQL Read Replicas**:
```yaml
postgres_primary:
  image: postgres:15

postgres_replica:
  image: postgres:15
  environment:
    - POSTGRES_PRIMARY_HOST=postgres_primary
```

---

## ğŸŒŸ Future Enhancements Roadmap

### Q1 2026

- [ ] **Multi-Algorithm Comparison**
  - Compare K-Means vs DBSCAN vs Hierarchical
  - Automated algorithm selection based on metrics

- [ ] **Real-time Streaming**
  - Apache Kafka integration
  - Stream processing with Apache Flink

- [ ] **Advanced Visualizations**
  - 3D interactive cluster plots (Three.js)
  - Animated transition between retraining runs

- [ ] **Mobile App**
  - React Native dashboard
  - Push notifications for drift alerts

### Q2 2026

- [ ] **A/B Testing Framework**
  - Compare model versions in production
  - Traffic splitting and gradual rollout

- [ ] **Automated Reporting**
  - PDF/Word report generation
  - Scheduled email reports

- [ ] **Multi-language Support**
  - Indonesian/English UI toggle
  - Internationalized (i18n) codebase

- [ ] **BI Tool Integration**
  - PowerBI/Tableau connectors
  - Pre-built dashboard templates

---

## ğŸ¬ Video Tutorials (Coming Soon)

### Planned Tutorial Series

1. **Getting Started (10 min)**
   - Installation walkthrough
   - First data upload
   - Viewing cluster results

2. **Admin Workflow (15 min)**
   - Data management
   - Pipeline triggering
   - Monitoring dashboards

3. **Model Interpretation (12 min)**
   - Understanding SHAP plots
   - Reading cluster statistics
   - Policy recommendations

4. **Advanced Configuration (20 min)**
   - Tuning Optuna parameters
   - Custom drift thresholds
   - Grafana dashboard creation

5. **Production Deployment (25 min)**
   - AWS EC2 setup
   - Security hardening
   - Continuous monitoring

---

## ğŸ’¬ Getting Help

### Support Channels

| Channel | Response Time | Best For |
|---------|---------------|----------|
| **GitHub Issues** | 24-48 hours | Bug reports, feature requests |
| **GitHub Discussions** | 12-24 hours | General questions, ideas |
| **Email** | 48-72 hours | Private inquiries, collaborations |
| **Documentation** | Instant | Step-by-step guides, troubleshooting |

### Before Asking for Help

Please provide:
1. âœ… Docker Compose version: `docker-compose --version`
2. âœ… Python version: `python --version`
3. âœ… Operating system: `uname -a` (Linux/Mac) or `ver` (Windows)
4. âœ… Error logs: `docker-compose logs [service]`
5. âœ… Steps to reproduce the issue

### Useful Debugging Commands

```bash
# View all container logs
docker-compose logs -f

# Check container resource usage
docker stats

# Inspect specific service
docker-compose exec [service] /bin/bash

# View network connections
docker network inspect devmlops_mlops-net

# Check volume contents
docker volume ls
docker volume inspect devmlops_postgres_data
```

---

## ğŸ“ Academic Citation

If you use this project in academic research, please cite:

```bibtex
@software{devmlops2025,
  author = {Agastya, Andiar Rinanda},
  title = {DevMLOps: End-to-End MLOps Pipeline for Education Readiness Clustering},
  year = {2025},
  url = {https://github.com/rynandasonduty/devmlops},
  note = {Machine Learning Technology Final Project}
}
```

---

## ğŸ† Acknowledgments

Special thanks to:

- **Mage AI Community** for the excellent orchestration platform
- **MLflow Team** for experiment tracking infrastructure
- **FastAPI Contributors** for the high-performance API framework
- **Streamlit Team** for enabling rapid dashboard development
- **Optuna Developers** for the powerful optimization framework
- **SHAP Contributors** for model interpretability tools
- **Evidently AI Team** for drift detection capabilities
- **Trivy & Bandit Teams** for security scanning tools
- **Indonesian Ministry of Education** for the public dataset
- **My Academic Supervisor** for guidance throughout this project
- **Open Source Community** for the amazing tools that made this possible

---

## ğŸ“ Contact & Support

**Author**: Andiar Rinanda Agastya

**Project Maintainer**: [@rynandasonduty](https://github.com/rynandasonduty)

**Contact Information:**
- ğŸ“§ Email: rynanda1202@gmail.com
- ğŸŒ GitHub: [@rynandasonduty](https://github.com/rynandasonduty)
- ğŸ’¼ LinkedIn: [Andiar Rinanda Agastya](https://linkedin.com/in/rynandasonduty)
- ğŸ¦ Twitter/X: [@thenamesagastya](https://twitter.com/thenamesagastya)

**Project Repository**: https://github.com/rynandasonduty/devmlops

**Documentation**: This README.md (comprehensive guide)

---

## ğŸ”„ Version History

| Version | Date | Changes |
|---------|------|---------|
| **v1.0.0** | 2025-12-01 | Initial release with core MLOps features |
| **v1.1.0** | 2025-12-08 | Added Admin Dashboard and CT pipeline |
| **v1.2.0** | 2025-12-16 | Implemented comprehensive monitoring with Grafana |
| **v1.3.0** | 2025-12-18 | Added SHAP analysis and enhanced security scanning |

---

## ğŸ¯ Project Goals Achievement

```
âœ… COMPLETED OBJECTIVES:

Business Goals:
âœ… Enable data-driven policy decisions for AI curriculum
âœ… Identify provincial clusters with similar readiness
âœ… Provide actionable insights for targeted interventions

Technical Goals:
âœ… Fully automated CI/CD/CT pipeline
âœ… Zero-downtime model updates
âœ… Comprehensive monitoring and alerting
âœ… Production-ready API (< 100ms latency)
âœ… Reproducible experiments (MLflow + DVC)

MLOps Goals:
âœ… Automated hyperparameter tuning (Optuna)
âœ… Model explainability (SHAP)
âœ… Data drift detection (Evidently)
âœ… Container security (Trivy)
âœ… Code security (Bandit)
âœ… Comprehensive observability (Prometheus + Grafana)

Quality Goals:
âœ… 80%+ test coverage
âœ… < 200ms API latency (p95)
âœ… < 1% error rate
âœ… < 10 minutes training time
âœ… Zero critical security vulnerabilities
```

---

<div align="center">

## â­ If this project helped you, please consider giving it a star!

### ğŸš€ Built with Modern MLOps Best Practices

**DevMLOps** demonstrates production-grade Machine Learning Operations integrating:
- ğŸ”„ Automated Pipelines (Mage AI)
- ğŸ“Š Experiment Tracking (MLflow)
- ğŸ¯ Hyperparameter Tuning (Optuna)
- ğŸ§  Model Explainability (SHAP)
- ğŸ” Drift Detection (Evidently)
- ğŸ›¡ï¸ Security Scanning (Trivy + Bandit)
- ğŸ“ˆ Observability (Prometheus + Grafana)

**Ready for Production â€¢ Fully Documented â€¢ Open Source**

---

### ğŸ“š Complete Documentation Includes:
âœ… Installation Guide (5-minute quickstart)
âœ… End-to-End Case Study (Admin workflow)
âœ… API Documentation (OpenAPI/Swagger)
âœ… Monitoring Setup (Grafana dashboards)
âœ… Security Best Practices (Production checklist)
âœ… Troubleshooting Guide (Common issues & solutions)
âœ… Tool Explanations (SHAP, Optuna, Trivy, Bandit, etc.)

---

**Built with â¤ï¸ for Machine Learning Technology Final Project**

Â© 2025 Andiar Rinanda Agastya

[ğŸ“§ Email](mailto:rynanda1202@gmail.com) â€¢ [ğŸŒ GitHub](https://github.com/rynandasonduty) â€¢ [ğŸ’¼ LinkedIn](https://linkedin.com/in/rynandasonduty)

---

**âš¡ Quick Links:**
[Installation](#-installation-guide) â€¢
[Usage](#-usage-guide) â€¢
[API Docs](#-api-documentation) â€¢
[Monitoring](#-monitoring--observability) â€¢
[Troubleshooting](#-troubleshooting)

</div>

---

**END OF DOCUMENTATION**

*Last Updated: December 18, 2025*
*Document Version: 1.3.0*
*Total Pages: ~50 (when printed)*
*Reading Time: ~45 minutes*

#### 1. **View Cluster Analysis** (User Dashboard)

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant Backend
    participant Model

    User->>Frontend: Access http://localhost:8501
    Frontend->>Backend: GET /
    Backend-->>Frontend: Model status
    Frontend->>Frontend: Load cluster data
    Frontend->>Frontend: Render interactive map
    Frontend-->>User: Display dashboard
    User->>Frontend: Adjust policy parameters
    Frontend->>Frontend: Recalculate projections
    Frontend-->>User: Update visualizations
```

**Steps:**
1. Navigate to http://localhost:8501
2. Explore the **interactive Indonesia map** showing cluster assignments
3. View **cluster statistics** and **policy recommendations**
4. Use the **Policy Simulator** to model intervention impacts
5. Download **cluster reports** in CSV format

#### 2. **Upload New Data & Retrain Model** (Admin Dashboard)

```mermaid
sequenceDiagram
    participant Admin
    participant Frontend
    participant Mage
    participant MLflow
    participant Backend

    Admin->>Frontend: Login to Admin Dashboard
    Admin->>Frontend: Upload new CSV file
    Frontend->>Frontend: Validate data schema
    Frontend->>Frontend: Save to /data/raw/
    Admin->>Frontend: Click "Update Database"
    Frontend->>Mage: Trigger seeding pipeline
    Mage->>Mage: Load CSV to PostgreSQL
    Mage-->>Frontend: Seeding complete
    Admin->>Frontend: Click "Retrain Model"
    Frontend->>Mage: Trigger training pipeline
    Mage->>Mage: Extract, Clean, Scale
    Mage->>Mage: Train K-Means with Optuna
    Mage->>MLflow: Log metrics & model
    MLflow-->>Mage: Model registered
    Mage-->>Frontend: Training complete
    Backend->>MLflow: Load new model
    Frontend-->>Admin: Success notification
```

**Steps:**
1. Access **Admin Dashboard** (password: `admin123`)
2. Navigate to **"Data Upload"** tab
3. Upload CSV file (must contain required columns)
4. Click **"Save CSV to Server"**
5. Click **"Update Database (Run Seeding)"**
6. Navigate to **"Pipeline Control"** tab
7. Click **"Trigger Pipeline Now"**
8. Monitor progress in real-time (2-5 minutes)
9. View updated predictions in User Dashboard

#### 3. **Make API Predictions** (Programmatic Access)

```bash
# Example: Predict cluster for custom input
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "persen_sekolah_internet_sd": 85.0,
    "persen_sekolah_internet_smp": 90.0,
    "persen_sekolah_internet_sma": 95.0,
    "persen_guru_sertifikasi_sd": 45.0,
    "persen_guru_sertifikasi_smp": 50.0,
    "persen_guru_sertifikasi_sma": 60.0,
    "rasio_siswa_guru_sd": 18.0,
    "rasio_siswa_guru_smp": 16.0,
    "rasio_siswa_guru_sma": 15.0,
    "rasio_siswa_komputer_sd": 25.0,
    "rasio_siswa_komputer_smp": 20.0,
    "rasio_siswa_komputer_sma": 15.0,
    "persen_lulus_akm_literasi": 65.0,
    "persen_lulus_akm_numerasi": 60.0,
    "persen_sekolah_listrik_sd": 98.0,
    "persen_sekolah_listrik_smp": 99.0,
    "persen_sekolah_listrik_sma": 100.0,
    "persen_guru_kualifikasi_s1_sd": 80.0,
    "persen_guru_kualifikasi_s1_smp": 85.0,
    "persen_guru_kualifikasi_s1_sma": 90.0
  }'
```

**Response:**
```json
{
  "cluster_id": 2,
  "label": "Tinggi (High Readiness)",
  "message": "Prediksi berhasil"
}
```

---

## ğŸ”„ Pipeline Workflows

### Training Pipeline Architecture

```mermaid
graph TD
    A[Start: Pipeline Trigger] --> B[Load Data from PostgreSQL]
    B --> C[Data Cleaning: IQR Outlier Removal]
    C --> D[Feature Standardization]
    D --> E{Drift Detection}
    E -->|No Drift + Model Exists| F[Pipeline Stop]
    E -->|Drift Detected OR No Model| G[Hyperparameter Tuning with Optuna]
    G --> H[Train K-Means k=2,3,4,5,6]
    H --> I[Select Best k by Silhouette Score]
    I --> J[Log to MLflow]
    J --> K[Save Model & Scaler Artifacts]
    K --> L[Generate Visualizations]
    L --> M[Generate SHAP Explanations]
    M --> N[Export Labeled Data]
    N --> O[End: Model Ready]

    style E fill:#f59e0b
    style G fill:#3b82f6
    style J fill:#10b981
```

### Pipeline Blocks Detailed

| Block Name | Type | Input | Output | Purpose |
|------------|------|-------|--------|---------|
| `load_education_features` | Data Loader | PostgreSQL | DataFrame | Extract data from database |
| `clean_outliers_iqr` | Transformer | DataFrame | Cleaned DataFrame | Remove extreme values using IQR method |
| `transform_standardize` | Transformer | DataFrame | Scaled DataFrame | Standardize features (mean=0, std=1) |
| `generate_drift_report` | Data Exporter | DataFrame | HTML Report + Metrics | Detect data drift, trigger CT logic |
| `train_kmeans_clustering` | Data Exporter | DataFrame | Trained Model + Metadata | Train and register optimal model |
| `generate_visualizations` | Custom | DataFrame | PNG Images | Create Elbow, Silhouette, PCA plots |
| `explain_model_shap` | Custom | Model + Data | SHAP Plot | Generate feature importance visualization |

### Continuous Training (CT) Logic

```python
# Pseudocode from generate_drift_report.py
if not model_exists():
    continue_to_training()  # Cold start
elif drift_detected(current_data, reference_data):
    continue_to_training()  # Drift trigger
else:
    stop_pipeline()  # Save resources
```

**Drift Metrics Monitored:**
- **Dataset Drift**: Boolean flag (True/False)
- **Drift Share**: Percentage of features exhibiting drift (0.0-1.0)
- **Statistical Tests**: Kolmogorov-Smirnov test per feature

---

## ğŸ“¡ API Documentation

### Endpoints

#### 1. **Health Check**

```http
GET /
```

**Response:**
```json
{
  "status": "active",
  "model_status": "Loaded"
}
```

#### 2. **Cluster Prediction**

```http
POST /predict
Content-Type: application/json
```

**Request Body Schema:**
```json
{
  "persen_sekolah_internet_sd": float,      // SD internet access %
  "persen_sekolah_internet_smp": float,     // SMP internet access %
  "persen_sekolah_internet_sma": float,     // SMA internet access %
  "persen_guru_sertifikasi_sd": float,      // SD certified teachers %
  "persen_guru_sertifikasi_smp": float,     // SMP certified teachers %
  "persen_guru_sertifikasi_sma": float,     // SMA certified teachers %
  "rasio_siswa_guru_sd": float,             // SD student-teacher ratio
  "rasio_siswa_guru_smp": float,            // SMP student-teacher ratio
  "rasio_siswa_guru_sma": float,            // SMA student-teacher ratio
  "rasio_siswa_komputer_sd": float,         // SD student-computer ratio
  "rasio_siswa_komputer_smp": float,        // SMP student-computer ratio
  "rasio_siswa_komputer_sma": float,        // SMA student-computer ratio
  "persen_lulus_akm_literasi": float,       // Literacy pass rate %
  "persen_lulus_akm_numerasi": float,       // Numeracy pass rate %
  "persen_sekolah_listrik_sd": float,       // SD electricity access %
  "persen_sekolah_listrik_smp": float,      // SMP electricity access %
  "persen_sekolah_listrik_sma": float,      // SMA electricity access %
  "persen_guru_kualifikasi_s1_sd": float,   // SD S1-qualified teachers %
  "persen_guru_kualifikasi_s1_smp": float,  // SMP S1-qualified teachers %
  "persen_guru_kualifikasi_s1_sma": float   // SMA S1-qualified teachers %
}
```

**Response:**
```json
{
  "cluster_id": 2,
  "label": "Tinggi (High Readiness)",
  "message": "Prediksi berhasil"
}
```

**Error Response (503 Service Unavailable):**
```json
{
  "detail": "Model belum siap. Jalankan pipeline training dulu."
}
```

#### 3. **Prometheus Metrics**

```http
GET /metrics
```

**Exposed Metrics:**
- `http_requests_total` - Total HTTP requests
- `http_request_duration_seconds` - Request latency histogram
- `http_requests_inprogress` - In-flight requests

---

## ğŸ‘ï¸ Monitoring & Observability

### Prometheus Metrics Collection

```mermaid
graph LR
    A[Backend API] --> B[Prometheus]
    C[Node Exporter] --> B
    D[cAdvisor] --> B
    E[Postgres Exporter] --> B
    F[Pushgateway] --> B
    B --> G[Grafana]
    B --> H[Alertmanager]
    H --> I[Email Notifications]
```

### Key Dashboards

#### 1. **Golden Signals Dashboard (Grafana)**

| Signal | Metric | Threshold | Alert |
|--------|--------|-----------|-------|
| **Latency** | `http_request_duration_seconds` | p99 < 500ms | Warning |
| **Traffic** | `http_requests_total` rate | - | Info |
| **Errors** | `http_requests_total{status=~"5.."}` | < 5% | Critical |
| **Saturation** | `container_memory_usage_bytes` | < 80% | Warning |

#### 2. **Data Drift Dashboard (Evidently)**

Accessible via Admin Dashboard â†’ **Monitoring** tab

**Visualizations:**
- Feature-by-feature drift scores
- Distribution comparison plots
- P-value heatmaps
- Data quality metrics

#### 3. **Infrastructure Dashboard (Grafana)**

**Metrics Tracked:**
- CPU usage per container
- Memory consumption
- Disk I/O
- Network traffic
- Database connection pool

### Alerting Rules

**Example Alert (from `alert_rules.yml`):**

```yaml
- alert: HighErrorRate
  expr: |
    sum(rate(http_requests_total{status=~"5.."}[1m]))
    / sum(rate(http_requests_total[1m])) > 0.05
  for: 2m
  labels:
    severity: critical
  annotations:
    summary: 'High Error Rate on Backend API'
```

**Email Notification Template:**
```
Subject: ğŸš¨ [DevMLOps Alert] High Error Rate

Alert: HighErrorRate
Severity: critical
Status: firing
Instance: backend:8000

Description:
The backend API error rate has exceeded 5% for the past 2 minutes.
Current value: 7.3%

Action Required: Check backend logs and investigate root cause.
```

---

## ğŸš€ CI/CD/CT Pipeline

### GitHub Actions Workflows

#### 1. **CI Pipeline** (`.github/workflows/ci_pipeline.yml`)

```mermaid
graph TD
    A[Push to main] --> B{Quality Check}
    B --> C[Ruff Linting]
    B --> D[Black Formatting]
    B --> E[Bandit Security Scan]
    C --> F[Unit Tests]
    D --> F
    E --> F
    F --> G{Container Security}
    G --> H[Build Docker Image]
    H --> I[Trivy Vulnerability Scan]
    I --> J{Pass?}
    J -->|Yes| K[Success âœ…]
    J -->|No| L[Fail âŒ]
```

**Stages:**

| Stage | Tool | Purpose | Fail Condition |
|-------|------|---------|----------------|
| Lint | Ruff | Catch syntax errors, unused imports | Any error found |
| Format | Black | Enforce PEP-8 style | Code not formatted |
| Security | Bandit | Detect security issues (SQL injection, etc.) | High/Critical issues |
| Test | pytest | Validate functionality | Any test failure |
| Container Scan | Trivy | Find CVEs in Docker images | Critical vulnerabilities |

#### 2. **CML Pipeline** (`.github/workflows/cml_pipeline.yml`)

```mermaid
sequenceDiagram
    participant PR as Pull Request
    participant GHA as GitHub Actions
    participant Model as Training Script
    participant CML as CML Tool

    PR->>GHA: Trigger on PR
    GHA->>Model: Run lightweight training
    Model->>Model: Generate metrics.txt
    Model->>Model: Create cluster_preview.png
    Model->>CML: Send results
    CML->>PR: Post comment with metrics & plot
```

**Output Example:**

```markdown
## ğŸ¤– CML Model Report
Hasil training otomatis dari PR ini:

### ğŸ“Š Metrics
Silhouette Score: 0.4523
Inertia: 1234.56

### ğŸ“ˆ Visualisasi
![](./cluster_preview.png)
```

#### 3. **Continuous Training Trigger**

**Automated CT Scenarios:**

| Scenario | Trigger | Action |
|----------|---------|--------|
| **Cold Start** | No model exists | Train immediately |
| **Drift Detected** | `drift_score > 0.15` | Retrain model |
| **Scheduled** | Monthly cron job | Periodic refresh |
| **Manual** | Admin dashboard button | On-demand training |

---

## ğŸ“Š Model Performance

### Hyperparameter Tuning Results

**Optuna Optimization History:**

| Trial | n_clusters | Silhouette Score | Davies-Bouldin | Combined Score | Selected |
|-------|-----------|------------------|----------------|----------------|----------|
| 1 | 2 | 0.3845 | 1.2341 | 0.0143 | âŒ |
| 2 | 3 | 0.4523 | 1.0234 | 0.1452 | âŒ |
| 3 | 4 | 0.4012 | 1.1567 | 0.0542 | âŒ |
| 4 | 5 | 0.3678 | 1.3012 | -0.0226 | âŒ |
| 5 | 6 | 0.3234 | 1.4123 | -0.0713 | âŒ |
| **Best** | **3** | **0.4523** | **1.0234** | **0.1452** | âœ… |

**Optimization Objective:**
```python
combined_score = silhouette_score - (0.3 * davies_bouldin_score)
```

### Model Metrics

**Production Model (k=3):**

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **Silhouette Score** | 0.452 | Good cluster separation (0.4-0.5 range) |
| **Davies-Bouldin Index** | 1.023 | Well-separated clusters (lower is better) |
| **Inertia (WCSS)** | 1,234.56 | Within-cluster sum of squares |
| **Calinski-Harabasz** | 187.43 | High inter-cluster to intra-cluster variance ratio |

### Cluster Statistics

**Distribution Across Indonesian Provinces (N=38):**

| Cluster | Label | Count | Percentage | Avg Infrastructure | Avg SDM | Avg Student Score |
|---------|-------|-------|------------|-------------------|---------|-------------------|
| **0** | Low Readiness | 12 | 31.6% | 54.3% | 38.7% | 52.1 |
| **1** | Medium Readiness | 15 | 39.5% | 73.2% | 58.4% | 64.8 |
| **2** | High Readiness | 11 | 28.9% | 89.7% | 78.9% | 75.3 |

**Example Provinces per Cluster:**

- **ğŸ”´ Low**: Papua, Maluku, NTT, Papua Barat, Sulawesi Barat
- **ğŸŸ¡ Medium**: Sumatera Barat, Sulawesi Selatan, Kalimantan Timur, NTB
- **ğŸŸ¢ High**: DKI Jakarta, Jawa Barat, Jawa Tengah, Jawa Timur, Bali

### Feature Importance (SHAP Analysis)

```mermaid
graph LR
    A[Top Features] --> B[Internet Access SMA: 0.342]
    A --> C[Certified Teachers SMP: 0.287]
    A --> D[Student-Computer Ratio SD: 0.234]
    A --> E[AKM Numeracy Score: 0.198]
    A --> F[S1 Qualified Teachers SMA: 0.176]

    style B fill:#ef4444
    style C fill:#f59e0b
    style D fill:#fbbf24
```

**Interpretation:**
- **Internet access at high school level** is the strongest predictor of cluster assignment
- **Teacher certification** (especially middle school) significantly impacts readiness
- **Technology access** (computer ratios) directly correlates with AI curriculum readiness
- **Student assessment scores** validate infrastructure/SDM quality alignment

---

## ğŸ“‹ Data Schema

### Input Features (20 Features)

#### 1. **Infrastructure (6 Features)**

| Feature | Type | Range | Description |
|---------|------|-------|-------------|
| `persen_sekolah_internet_sd` | float | 0-100 | Percentage of elementary schools with internet |
| `persen_sekolah_internet_smp` | float | 0-100 | Percentage of middle schools with internet |
| `persen_sekolah_internet_sma` | float | 0-100 | Percentage of high schools with internet |
| `persen_sekolah_listrik_sd` | float | 0-100 | Percentage of elementary schools with electricity |
| `persen_sekolah_listrik_smp` | float | 0-100 | Percentage of middle schools with electricity |
| `persen_sekolah_listrik_sma` | float | 0-100 | Percentage of high schools with electricity |

#### 2. **Human Resources - Teacher Quality (6 Features)**

| Feature | Type | Range | Description |
|---------|------|-------|-------------|
| `persen_guru_sertifikasi_sd` | float | 0-100 | Percentage of certified teachers (elementary) |
| `persen_guru_sertifikasi_smp` | float | 0-100 | Percentage of certified teachers (middle) |
| `persen_guru_sertifikasi_sma` | float | 0-100 | Percentage of certified teachers (high) |
| `persen_guru_kualifikasi_s1_sd` | float | 0-100 | Percentage of S1-qualified teachers (elementary) |
| `persen_guru_kualifikasi_s1_smp` | float | 0-100 | Percentage of S1-qualified teachers (middle) |
| `persen_guru_kualifikasi_s1_sma` | float | 0-100 | Percentage of S1-qualified teachers (high) |

#### 3. **Human Resources - Teaching Load (3 Features)**

| Feature | Type | Range | Description |
|---------|------|-------|-------------|
| `rasio_siswa_guru_sd` | float | 1-100 | Student-teacher ratio (elementary) |
| `rasio_siswa_guru_smp` | float | 1-100 | Student-teacher ratio (middle) |
| `rasio_siswa_guru_sma` | float | 1-100 | Student-teacher ratio (high) |

#### 4. **Technology Access (3 Features)**

| Feature | Type | Range | Description |
|---------|------|-------|-------------|
| `rasio_siswa_komputer_sd` | float | 1-1000+ | Student-computer ratio (elementary) |
| `rasio_siswa_komputer_smp` | float | 1-1000+ | Student-computer ratio (middle) |
| `rasio_siswa_komputer_sma` | float | 1-1000+ | Student-computer ratio (high) |

#### 5. **Student Outcomes (2 Features)**

| Feature | Type | Range | Description |
|---------|------|-------|-------------|
| `persen_lulus_akm_literasi` | float | 0-100 | Literacy assessment pass rate |
| `persen_lulus_akm_numerasi` | float | 0-100 | Numeracy assessment pass rate |

### Output Schema

```json
{
  "cluster_id": integer,        // 0, 1, or 2
  "label": string,              // "Rendah (Low)", "Sedang (Medium)", "Tinggi (High)"
  "message": string             // "Prediksi berhasil"
}
```

### Database Tables

#### **education_features** (Main Table)

```sql
CREATE TABLE education_features (
    provinsi VARCHAR(100) PRIMARY KEY,
    persen_sekolah_internet_sd FLOAT,
    persen_sekolah_internet_smp FLOAT,
    persen_sekolah_internet_sma FLOAT,
    persen_guru_sertifikasi_sd FLOAT,
    persen_guru_sertifikasi_smp FLOAT,
    persen_guru_sertifikasi_sma FLOAT,
    rasio_siswa_guru_sd FLOAT,
    rasio_siswa_guru_smp FLOAT,
    rasio_siswa_guru_sma FLOAT,
    rasio_siswa_komputer_sd FLOAT,
    rasio_siswa_komputer_smp FLOAT,
    rasio_siswa_komputer_sma FLOAT,
    persen_lulus_akm_literasi FLOAT,
    persen_lulus_akm_numerasi FLOAT,
    persen_sekolah_listrik_sd FLOAT,
    persen_sekolah_listrik_smp FLOAT,
    persen_sekolah_listrik_sma FLOAT,
    persen_guru_kualifikasi_s1_sd FLOAT,
    persen_guru_kualifikasi_s1_smp FLOAT,
    persen_guru_kualifikasi_s1_sma FLOAT
);
```

---

## ğŸ› ï¸ Development Guidelines

### Setting Up Development Environment

1. **Create Virtual Environment**

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# OR
venv\Scripts\activate     # Windows
```

2. **Install Dependencies**

```bash
pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt
pip install -r mage_pipeline/requirements.txt
```

3. **Install Pre-commit Hooks**

```bash
pip install pre-commit
pre-commit install
```

4. **Run Tests Locally**

```bash
pytest tests/
```

### Code Quality Standards

**Pre-commit Hooks Configuration:**

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml

  - repo: https://github.com/astral-sh/ruff-pre-commit
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]

  - repo: https://github.com/psf/black
    hooks:
      - id: black

  - repo: https://github.com/pre-commit/mirrors-prettier
    hooks:
      - id: prettier
        types_or: [yaml, markdown, json]
```

**Code Style:**
- **Python**: PEP-8 compliant (enforced by Black & Ruff)
- **Line Length**: 88 characters (Black default)
- **Import Sorting**: Automatic via Ruff
- **Type Hints**: Encouraged but not mandatory

### Adding New Features

#### **Adding a New ML Feature**

1. Update data schema in PostgreSQL
2. Modify `mage_pipeline/project_education/transformers/transform_standardize.py`
3. Update API schema in `backend/app/main.py` (Pydantic model)
4. Add feature to frontend input forms
5. Retrain model with new features
6. Update documentation

#### **Adding a New Visualization**

1. Create new block in `mage_pipeline/project_education/custom/`
2. Save plots to `/home/src/artifacts/`
3. Add display logic in frontend dashboard
4. Update nginx configuration if needed

#### **Adding a New Dashboard Page**

1. Create new file in `frontend/pages/`
2. Follow existing naming convention: `New_Page_Name.py`
3. Import shared CSS and utilities from `Homepage.py`
4. Add navigation link in sidebar
5. Test responsive design on mobile

### Testing Guidelines

**Test Structure:**

```python
# tests/test_feature.py
import pytest
from fastapi.testclient import TestClient

def test_feature_functionality():
    """Test description"""
    # Arrange
    test_data = {...}

    # Act
    result = function_under_test(test_data)

    # Assert
    assert result == expected_output
```

**Running Specific Tests:**

```bash
# Run all tests
pytest

# Run specific file
pytest tests/test_api.py

# Run with coverage
pytest --cov=backend --cov-report=html
```

---

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. **Port Already in Use**

**Symptom:**
```
Error: bind: address already in use
```

**Solution:**
```bash
# Find process using port
lsof -i :8501  # For Streamlit
lsof -i :8000  # For FastAPI

# Kill process
kill -9 <PID>

# OR change port in docker-compose.yml
ports:
  - "8502:8501"  # Host:Container
```

#### 2. **Model Not Loading in Backend**

**Symptom:**
```
Model belum siap. Jalankan pipeline training dulu.
```

**Solution:**
```bash
# Check if artifacts exist
ls -la mage_pipeline/artifacts/

# If missing, run training pipeline
docker-compose exec mage /bin/bash
# Inside container:
python -m mage_ai.cli.main run cluster_training_pipeline
```

#### 3. **Data Drift Report Not Generating**

**Symptom:**
```
FileNotFoundError: data_drift_report.html
```

**Solution:**
```bash
# Check Evidently version compatibility
docker-compose exec mage pip list | grep evidently

# Ensure version 0.6.0
pip install evidently==0.6.0

# Rerun drift detection block
```

#### 4. **Prometheus Not Scraping Metrics**

**Symptom:**
- Grafana shows "No data"
- Prometheus UI shows target down

**Solution:**
```bash
# Check Prometheus targets
curl http://localhost:9090/api/v1/targets

# Verify backend is exposing metrics
curl http://localhost:8000/metrics

# Check prometheus.yml configuration
docker-compose exec prometheus cat /etc/prometheus/prometheus.yml
```

#### 5. **Database Connection Error**

**Symptom:**
```
psycopg2.OperationalError: could not connect to server
```

**Solution:**
```bash
# Check if PostgreSQL is running
docker-compose ps postgres

# Check connection string
docker-compose exec mage env | grep POSTGRES

# Test connection manually
docker-compose exec postgres psql -U mlops_user -d education_db
```

### Debug Mode

**Enable verbose logging:**

```yaml
# docker-compose.yml
services:
  backend:
    environment:
      - LOG_LEVEL=DEBUG

  mage:
    environment:
      - MAGE_LOG_LEVEL=DEBUG
```

**View logs:**

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f backend
docker-compose logs -f mage

# Last 100 lines
docker-compose logs --tail=100 backend
```

### Performance Optimization

**Slow Training Pipeline:**

1. **Reduce Optuna trials**: Edit `train_kmeans_clustering.py`
   ```python
   study.optimize(lambda trial: objective(trial, X), n_trials=10)  # Was 15
   ```

2. **Skip visualization generation** (comment out in pipeline)

3. **Use smaller data sample** for development:
   ```sql
   SELECT * FROM education_features LIMIT 20;
   ```

**High Memory Usage:**

```bash
# Check container stats
docker stats

# Limit container memory
docker-compose.yml:
  backend:
    deploy:
      resources:
        limits:
          memory: 1G
```

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these guidelines:

### Contribution Workflow

```mermaid
graph TD
    A[Fork Repository] --> B[Create Feature Branch]
    B --> C[Make Changes]
    C --> D[Write Tests]
    D --> E[Run Pre-commit Hooks]
    E --> F{Tests Pass?}
    F -->|No| C
    F -->|Yes| G[Commit Changes]
    G --> H[Push to Fork]
    H --> I[Create Pull Request]
    I --> J[CI/CD Checks]
    J --> K{Approved?}
    K -->|No| L[Address Feedback]
    L --> C
    K -->|Yes| M[Merge to Main]
```

### Branch Naming Convention

- `feature/add-new-metric` - New features
- `bugfix/fix-api-error` - Bug fixes
- `docs/update-readme` - Documentation
- `refactor/optimize-pipeline` - Code refactoring
- `test/add-unit-tests` - Test additions

### Commit Message Format

```
type(scope): subject

body (optional)

footer (optional)
```

**Examples:**
```
feat(api): add endpoint for batch predictions

Implements /predict/batch endpoint that accepts multiple
input samples and returns predictions for all.

Closes #123
```

```
fix(dashboard): resolve map rendering issue

The Indonesia map was not loading due to incorrect GeoJSON
path reference. Updated path to use absolute URL.
```

### Pull Request Template

```markdown
## Description
Brief description of changes

## Type of Change
- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change
- [ ] Documentation update

## Testing
- [ ] Unit tests added/updated
- [ ] Integration tests pass
- [ ] Manual testing completed

## Checklist
- [ ] Code follows style guidelines
- [ ] Self-review completed
- [ ] Documentation updated
- [ ] No new warnings generated
```

### Code Review Criteria

**Reviewers will check:**
- [ ] Code quality and readability
- [ ] Test coverage (>80% for new code)
- [ ] Documentation completeness
- [ ] No security vulnerabilities
- [ ] Performance impact
- [ ] Backward compatibility

---

## ğŸ“š Additional Resources

### Documentation

- **Mage AI**: https://docs.mage.ai/
- **MLflow**: https://mlflow.org/docs/latest/
- **FastAPI**: https://fastapi.tiangolo.com/
- **Streamlit**: https://docs.streamlit.io/
- **Prometheus**: https://prometheus.io/docs/
- **Evidently AI**: https://docs.evidentlyai.com/

### Related Papers

1. **K-Means Clustering**: Lloyd, S. (1982). "Least squares quantization in PCM"
2. **Silhouette Score**: Rousseeuw, P. J. (1987). "Silhouettes: a graphical aid to the interpretation and validation of cluster analysis"
3. **MLOps Best Practices**: Sculley et al. (2015). "Hidden Technical Debt in Machine Learning Systems"

### Community

- **GitHub Issues**: https://github.com/rynandasonduty/devmlops/issues
- **Discussions**: https://github.com/rynandasonduty/devmlops/discussions
- **Email Support**: rynanda1202@gmail.com
- **Twitter/X**: @thenamesagastya

---

## ğŸ“„ License

This project is licensed under the **MIT License**.

```
MIT License

Copyright (c) 2025 Andiar Rinanda Agastya

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Acknowledgments

Special thanks to:

- **Mage AI Community** for the excellent orchestration platform
- **MLflow Team** for experiment tracking infrastructure
- **FastAPI Contributors** for the high-performance API framework
- **Streamlit Team** for enabling rapid dashboard development
- **Indonesian Ministry of Education** for the public dataset
- **My Academic Supervisor** for guidance throughout this project

---

## ğŸ“ Contact & Support

**Author**: Andiar Rinanda Agastya

**Project Maintainer**: [@rynandasonduty](https://github.com/rynandasonduty)

**Contact Information:**
- ğŸ“§ Email: rynanda1202@gmail.com
- ğŸŒ GitHub: [@rynandasonduty](https://github.com/rynandasonduty)
- ğŸ’¼ LinkedIn: [Andiar Rinanda Agastya](https://linkedin.com/in/rynandasonduty)
- ğŸ¦ Twitter/X: [@thenamesagastya](https://twitter.com/thenamesagastya)

**Project Repository**: https://github.com/rynandasonduty/devmlops

---

## ğŸ”„ Version History

| Version | Date | Changes |
|---------|------|---------|
| **v1.0.0** | 2025-12-18 | Initial release with core MLOps features |
| **v1.1.0** | 2025-12-19 | Added Admin Dashboard and CT pipeline |
| **v1.2.0** | 2025-12-20 | Implemented comprehensive monitoring |

---

## ğŸ¯ Roadmap

### Planned Features (Q1 2026)

- [ ] **Multi-model comparison**: Compare K-Means with DBSCAN, Hierarchical Clustering
- [ ] **Real-time streaming**: Apache Kafka integration for live data updates
- [ ] **Advanced visualizations**: 3D cluster plots, interactive dendrograms
- [ ] **Mobile application**: React Native dashboard for mobile access
- [ ] **A/B testing framework**: Compare model versions in production
- [ ] **Automated reporting**: PDF/Word report generation from dashboard
- [ ] **Multi-language support**: Indonesian/English UI toggle
- [ ] **Export to BI tools**: PowerBI/Tableau connector

### Future Enhancements

- [ ] **Deep Learning integration**: AutoML for feature engineering
- [ ] **Federated learning**: Privacy-preserving distributed training
- [ ] **Explainable AI**: LIME integration alongside SHAP
- [ ] **Cloud deployment**: AWS/GCP/Azure deployment guides
- [ ] **Edge deployment**: TensorFlow Lite model conversion
- [ ] **API rate limiting**: Redis-based throttling
- [ ] **WebSocket support**: Real-time updates to dashboard
- [ ] **Audit logging**: Comprehensive user action tracking

---

<div align="center">

### â­ If this project helped you, please consider giving it a star!

**Built with â¤ï¸ for Machine Learning Technology Final Project**

Â© 2025 Andiar Rinanda Agastya â€¢ [GitHub](https://github.com/rynandasonduty) â€¢ [Email](mailto:rynanda1202@gmail.com)

</div>
